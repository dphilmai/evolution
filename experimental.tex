\label{sec:experimentalevidence}
A third approach beside the traditional and the evolutionary treatment of 
coordination problems is what \textcite{camerer_behavioral_2003} calls the 
'fundamental empirical' approach.
Hence, this section consults the experimental economic literature regarding 
laboratory coordination games to provide evidence how actual people choose
their strategies in such situations and which factors might influence them. 
Precisely, do people, if they are able to coordinate on an equilibrium at all,
play the risk-dominant or the payoff-dominant equilibrium? And how does their
choice change playing the game repeatedly?
Due to the rich experimental literature on coordination in social 
dilemmas, the focus will be on studies with framework close to  
evolutionary SH game. A comparison will show the shortcomings and what
is described well by the evolutionary framework.
 
Due to the different notations authors use, a translation into the present
notation was performed.
On these grounds, the 
strategy used in the payoff-dominant equilibrium of the SH game will be 
either called  \textit{strategy S} or in analogy to the stag hunt story 
\textit{hunting stag}.
Consistently, the strategy used in the risk-dominant equilibrium is called
\textit{strategy H} or \textit{hunting hare}.

The papers of \textcite{van_huyck_tacit_1990} and 
\textcite{cooper_communication_1992} are seen as the first experiments 
investigating coordination games \parencite{devetag_when_2007}.
In \textcite{van_huyck_tacit_1990}, subjects do not play a stag
hunt, but an order-statistics game. These games differ in that subjects can
choose from a broader set of strategies, ordered from high to low, and 
hence there are more than two equilibria in the game. 
Played by a group, the players payoffs depend on the lowest strategy one of 
their group members chose, thus the name 'weak-link' order statistics game. 
Nevertheless, the structure is similiar to the stag hunt in the way 
that the equilibria are Pareto-ranked, with one 
'safe' strategy \parencite{devetag_when_2007}.
So evidence from this games is likely to be transferable to the 
coordination problem in the stag hunt game. 
In \textcite{van_huyck_tacit_1990} subjects played the order-statistics 
game in 
groups of 14-16 for 10 periods. They only received information about their 
payoff, but that was sufficient for the players to find out what the 
lowest choice of one subject in 
their group was. Astonishingly, in every experiment the groups converged
to the equilibrium with the lowest payoff. 
This result was preserved across all groups in another 
five periods of this game, although the subjects played an alternative payoff
matrix, embracing the payoff-efficient equilibrium, in between. 
Replications of this results have been performed numerously, with 
varying group sizes and slightly changed payoff matrices 
\parencite[6]{devetag_when_2007}. 
\textcite{cooper_communication_1992} used a
two-player stag hunt game\footnote{They call 
it simple coordination game (SCG).}  
and one augmented by a dominated strategy. They found that 
subjects in randomly matched one-shot games, knowing only about their own
received payoffs, also failed to coordinate without any preplay communication. 
However, they find that two-way communication, in which both players were
able to send a message to their matched partner containing which strategy
they intend to choose, solves the coordination problem in the SCG. 
In their game, both players had an incentive to truthfully tell their
opponents, ($c=d$). Therefore, this does not reject Aumanns's hypothesis.
Nevertheless, \textcite{clark_when_2001} run experiments with a game in which
players had an incentive to want their opponents to choose strategy $S$ 
independenty of their choice ($c \geq d$).
In this game, when both players announced $S$, only 25\% coordinated on
the Pareto-dominant equilibrium. Furthermore, they introduced a game
similiar to the typical stag hunt, but with $c<d$. Here, a player saying he 
intends to choose "S" is better of if the other player also chooses $S$, and
so "communication may be expected to be most credible in Aumann's sense" 
\parencite[508]{clark_when_2001}. They found that agreements on a strategy
helped to coordinate, but players equally agreed to the Pareto-dominated
equilibrium. 
All in all, preplay communication helps to coordinate, but which
equilibrium is reached depends on the payoff matrix.

However, the 
early approaches by \textcite{cooper_communication_1992} and
\textcite{van_huyck_tacit_1990} suggest that without cheap talk 
coordination failure\footnote{Here in the meaning of not being 
able to coordinate on the payoff-dominant equilibrium.} 
is common in the laboratory \parencite[2]{devetag_when_2007}. 

\subsection{Variation of the payoff matrix}
In the evolutionary games discussed above, a group of players is randomly
matched against each other to play a stag hunt game. For that reason, the
implementation of random matching in a group closely resembles an 
evolutionary game.

Random matching was conducted by \textcite{battalio_optimization_2001}. 
Subjects played three stag hunt games with the typical symmetric pure strategy
equilbrium and the symmetric mixed strategy equilibrium at $(0.8,0.2) \in
\Delta$. Figure \ref{fig:payoffbattalio} shows the payoff matrices of the
games $2R, R$ and $0.6R$ used. Note, that the game $2R$ does not satisfy the
condition for the parameters used throughout this text as $c<d$ ($35<40$).
The names become clear when observing the 
\textit{optimization premium} of the games. While controlling for the basin of 
attraction of the equilibria - the mixed equilibrium is equal in all games -
they want to explore the effect of an increase in the ``premium for playing
a best-response'' \parencite[751]{battalio_optimization_2001}. 
In order to investigate this, they define the optimization premium $r_j(y)$ of 
a game $j$ as the difference in payoffs choosing the pure strategies 
$e_1$ and $e_2$ while expecting the opponent to play a strategy 
$y=(q,1-q)^T \in \Delta$:
\begin{align}
        r_j(y)= \hat{F_j}(e_1,y) - \hat{F_j}(e_2,y) = \delta_j(q-q^*),
\end{align}
with the \textit{optimization premium parameter} $\delta_j$ and the 
probability used in the mixed strategy equilibrium $q^*$. In the notation
of the parametrized SH game, $\delta_j = a - c + d - b$. The optimization
premium is only different from zero, if a player expects the other player not
to use the mixed Nash equilibrium strategy.
The parameters for the payoff matrices used in this study 
are reported in figure \ref{fig:payoffbattalio}. 
First of all, they find support for their hypothesis that in games with a 
larger optimization premium subjects coordinate less frequently on the 
payoff-dominant equilibrium. 
In game $0.6R$ ($\delta_{0.6R}=50$) two cohorts and in $R$ ($\delta_{R}=25$)
one cohort converged to the payoff-dominant equilibrium. There was no
cohort in the game with the lowest optimization premium parameter, 
$\delta_{2R}= 15$, that coordinated on stag hunting.
The deterministc replicator dynamic does 
not offer a description of this behavior, since convergence to an 
equilibrium only depends on its basin of attraction once the dynamic 
started, which do not differ for the three games. 
Whereas ``all 24 cohorts start in the basin of attraction
of the risk-dominant equilibrium'' 
\parencite[755]{battalio_optimization_2001}, all should converge to the 
risk-dominant equilibrium according to the dynamic.
In most cases this is true, with only two exceptions in game $0.6R$ 
and one in $R$.
But, for the sake of completness, a crossing of the  
``best-response separatrix'' \parencite{battalio_optimization_2001} i.e. 
mixed-strategy equilibrium, can not happen in the deterministic replicator 
dynamic. Furthermore, as they conjectured, a larger optimization premium 
increases the speed of convergence. Hence, a coordination on a equilibrium 
was achieved fastest in the $2R$ game. This is consistend with a 
postulated replicator dynamic for this games. Starting from 
\eqref{eq:replicator}, one can derive that the dynamics of this 
games are the same up to a change in speed, proportional to the ratio of 
optimization premia of the games. In game $R$ the change in the population share
playing strategy $S$ is, thus, half the speed of $2R$ and four thirds of $0.6R$,
$\dot{x}_{R} = \frac 12 \dot{x}_{2R} = \frac{4}{3}\dot{x}_R$.

\textcite{schmidt_playing_2003} designed their experiment such that the effect
of differing risk levels could be observed. It is convenient to relabel 
the strategies in the game, because in their treatment the payoff-dominant 
equilibria is in the right corner of the normal form game representation,
contrary to the notation used throuhout this text. Comparing risk levels between
games, they used a measure due to \textcite{selten_axiomatic_1995}, defined
as:
\begin{align}
        \label{riskmeasureschmidt}
        R = ln\left(\frac{\hat{F}(e_2,e_2) -\hat{F}(e_2,e_1)}{\hat{F}(e_1,e_1) 
        -\hat{F}(e_2,e_1)}\right) = ln \left(\frac{d-b}{a-c}\right).
\end{align}
The risk measure $R$ is positive, if the Nash equilibrium $(e_2,e_2)$ is
risk-dominant, and negative if the payoff-dominant equilibrium inhibits both
properties.
None of the four games in \textcite{schmidt_playing_2003} handles
the case of $R=0$, where the mixed-strategy equilibrium is risk-dominant.
In difference to \textcite{battalio_optimization_2001}, they do not
use the proposed optimization premium, but rather measure the risk-dominance 
level in relative terms as $P=\frac{a-d}{a}$.\footnote{As they mention, the 
games in \textcite{battalio_optimization_2001} vary in their level of 
P accordingly.}
The payoff matrices of the games are shown in \ref{fig:payoffschmidt}.
Comparing game 2 with game 3, and game 1 with game 4, the 
only differ in their degree of risk-dominance and hence one can 
investigate if subjects react a change in $R$ ceteris paribus. 
For game 1 and game 3 the basin of attraction of both equilibria is equal 
(Mixed-NE at $(\frac 12, \frac 12)$) and  for
game 2 and 3 the Mixed-NE is at $(\frac 34,\frac 14)$ resulting in the 
typical  larger basin of attraction of the equilibrium $(e_2,e_2)$. 
Therefore, it is expected from the replicator dynamic, of course 
depending on the inital condition 
of the game, that subjetcs are more likely attracted to the hare hunting 
equilibrium in game 2 and 3.



In their implementation of a random matching protocol, 
\textcite{schmidt_playing_2003} found evidence that an increase in $R$
leads to a higher choice of the strategy in the risk-dominant Nash equilibrium.

First of all, a random matching protocol where each subject is not
matched twice with another person and only has information 
about his payoff and the action of the person he was matched against. 
Secondly, a fixed protocol, matching two persons for several rounds against 
each other, followed by a series of one-shot games. 





The risk measure $R$ indicates the risk concerned with a players own
deviation. As \textcite[19]{rydval_loss_2005} suggest "[R]ather than their
own deviation [...], players might worry about their opponent's choices", 
and hence a "definition of risk other than that embedded in the definition
of risk dominance" is necessary.
\textcite[371]{dubois_optimization_2012} 
introduced the \textit{relative riskiness} of a game as
$RR = \frac{|d-c|}{a-b}$.
Intuitively, a player commited to strategy $S$ receives $(a-b)$ less payoff 
when his opponent switches from strategy $S$ to $H$. Similiar thoughts lead
to a difference of $(c-d)$ for a player commited to strategy $H$. Hence, the
$RR$ is simply the ratio of this payoff differences caused by an opponents
deviation.
Alternatively, it can be interpreted as the ratio of the 
standard deviations of the payoffs 
\parencite[372]{dubois_optimization_2012}. 
The relative riskiness measure is close to one if both strategies involve
similiar risk. Accordingly, a lower relative riskiness measure implies that
strategy $H$ has a lower risk compared to strategy $S$.
Observing the values of the relative riskiness by 
\textcite{dubois_optimization_2012} and the risk-dominance measure of 
\textcite{schmidt_playing_2003} for the games used in the papers, it is clear
that both measures are in a conflict. As by the measure 
\textcite{schmidt_playing_2003} used, risk-dominance is kept 
constant in the games of  \textcite{battalio_optimization_2001}, 
whereas relative riskiness indicates a variation. 
On the other hand, relative riskiness cannot distinguish between
the games 1,2 and 3 of \textcite{schmidt_playing_2003}, since $RR=0$. In an
early working version of their paper they explicitly excluded the case 
$c \neq d$ and statet that ``a more general measure of relative riskiness 
should allow for the case where c=d as compared to $(a-b)$'' 
\parencite{dubois_optimization_2008}. 

The experimental desing of \textcite{dubois_optimization_2012} is similiar
to that of \textcite{battalio_optimization_2001}.
Game 1 replicated game $0.6R$  of \textcite{battalio_optimization_2001}  
(Compare figure \ref{fig:payoffdubois} and \ref{fig:payoffbattalio}). 
As per their conjecture, they found that a lower relative riskiness 
in a game decreases the rate players choose strategy $S$, 
keeping the optimization premium constant. This is congruent with 
the intuition that the severity of the impact connected to the uncertainty
about an opponents choice, expressed in
the difference in payoff a deviation of the opponent would cause,
effects a players strategy choice. 
On the other hand, keeping the relative riskiness constant and varying the
optimization premium, they cannot find an effect on the frequency of 
strategy $S$. 
In measuring the ``coordination sucess'', they deploy the concept of ``strong
coordination''. 
In other words, counting the occurence of periods in which a group
uniformly adopts a strategy such that every pair of subjects lands in one
of the Nash equilibria. \textcite{dubois_optimization_2012} intend to sort 
out ``furtuitous coordination'', coordination as consequence of subjects being
randomly matched with each other \parencite[373]{dubois_optimization_2012}.
Comparing strong coordinations between the games they find a non-significant 
difference between game 1 and game 2 in which only the relative riskiness 
ceteris paribus was changed. Contrary to that, there is a significant 
difference in the commonness in game 3 to game 2.
Since game 3 and 2 only differ in their optimization premium, 
\textcite{dubois_optimization_2012} conclude that a higher optimization
premium leads to more frequent (strong) coordination. 
As they mention, this agrees with the observation of 
\textcite{battalio_optimization_2001} that coordination success depends 
positively on the optimization premium. 

As seen from the evidence \textcite{battalio_optimization_2001},
\textcite{schmidt_playing_2003} and \textcite{dubois_optimization_2012} 
found, the structure of the payoff matrix has a strong impact on the way 
people play the stag hunt game.   
The story this evidence tells is quite frightening. Failure to coordinate 
on the payoff-dominant equilibrium seems to be common. 
Following an argument of \textcite{kreps_game_1990} that identical strategic 
interactions, such as the play of completely indentical stag hunt games 
in the laboratory, ``take us very little distance outside the laboratory'' 
\parencite[212]{kreps_game_1990}, 
\textcite{rankin_strategic_2000} design an experiment with a randomly 
pertubated stag hunt game. Essentially, the payoff to $S$strategy $S$ is fixed 
whereas the payoff to strategy $H$ varies randomly between the games. This is
depicted in the payoff matrix \eqref{eq:payoffrankin}.
\begin{align}
        \label{eq:payoffrankin}
        A = \mqty(1 & 0 \\ x & x)
\end{align}        
The parameter $x$ is equally distributed between $(0,1)$ and, once a sequence
was calculated, used for all cohorts participating in the experiment. This
variation justifies to describe the games as ``similiar'' but not
``identical'', hence the structure stays the same, but the risk-dominance 
property varies. Indeed, if $x$ is greater than $0.5$ risk-dominance and
payoff-dominance select different equilibria, $(e_2,e_2)$ and $(e_1,e_1)$,
respectively. For a value of $x$ smaller than $0.5$ both select 
the equilibrium in strategy $S$. One finds that the optimization premium for 
this randomly perturbed games does not change, since $\delta=1-x+x+0=1$. 
The relative riskiness measure $RR$ cannot discriminate between this games,
since $|d-c|=0\ \forall x$. \textcite{schmidt_playing_2003} measure of risk of 
course is positive for $x > 0.5$ and negative for $x <0.5$. 
The question \textcite{rankin_strategic_2000}
want to investigate is, if this framework of sligthly varied situations may
lead the groups to form a ``convention'' which deductive principle to choose. 
In contrast to the studies performed with identical stag hunt games, they 
observe coordination to the payoff dominant equilibrium across
all cohorts. Whereas in the first ten periods of play risk dominance seems
to have some explanatory power for the choice of strategy, in the last ten
rounds 91\% choose the payoff dominant action. 
In the cases of coinciding equilibrium selection of risk-dominance and 
payoff-dominance ($x < 0.5$) all subjects coordinated on that equilibrium in 
group 1-5 and 95\% of the subjects in group 6. But also for the other case a 
high coordination on the payoff-dominant strategy was observed, ranging from 
80\% to 95\% of the strategies played, suggesting that there is clear evidence
for the hypothesis of an emerging convention based on the deductive principle
payoff-dominance. Contrary to previous experiments, this sends 
a quite positive image about coordination, because 
this is ``dramatically at odds with claims that coordination failure is common''
\parencite[9]{devetag_when_2007}. 

Certainly, it is to suspect that real players, opposed to the agents
in the replicator dynamic who are following a simple imitation rule,
can take into account what strategies were played in the rounds before.
\textcite{battalio_optimization_2001} used a logistic-response model to
investigate if the optimization premium affects the reliance of subjects
on the history of play. Indeed, they found the highest sensitivity of 
individuals to previous rounds in game $2R$.
\textcite{dubois_optimization_2012} confirms this result, also using 
a logistic-response model. Additionally, they cannot reject the null
hypothesis that sensitivity to previous play is significantly different for
game 2 and 1. Hence, they do not find an effect of a change in the
relative riskiness. Interestingly, the logistic-response model can be
formulated as a single-population continous-time logistic-resonse dynamic
\parencite[752]{battalio_optimization_2001}. The derivation is due to
\textcite{fudenberg_theory_1998}. 


\subsection{Implementational details}
As outlined, most studies concerned with the stag hunt game in the 
laboratory focused on the characteristics of the payoff matrix. 
However, implementational details 
such as the matching protocol influence behaviour sharply. Not only 
\textcite{van_huyck_tacit_1990} found in their two-player fixed matching
convergence to the payoff-dominant equilibrium, 
\textcite{clark_repetition_2001} also found different strategy 
choices between randomly matched one-shot games and fixed matching protocol 
games. The latter lead to significantly higher choices of the strategy 
in the efficient equilibrium and less ``disequilibrium play'' in general
\parencite[]{clark_repetition_2001}. 
\textcite{devetag_when_2007} mention that one-shot games imply a 
random matching protocol. But it is different to random matching on group
basis, where subjects can play against the same opponent again 
and hence there is the possibility that a ``convention'' emerges like in 
\textcite{rankin_strategic_2000}.

Even more subtle experiment design differences are conjectured to have an
effect. For example \textcite{devetag_when_2007} suggest that the formulation
``you will remain grouped with the same seven other participants for the next
75 rounds'' in the instruction of the \textcite{rankin_strategic_2000}  
experiment may increased trust within the group and hence was a 
cause for the exceptional coordination success. Comparatively, the 
instructions in \textcite{dubois_optimization_2012} read ``At the beginning
of each period, in each group (composed of 8 participants), the computer
system will form 4 pairs of subjects. [...] The experiment 
involves 75 rounds''\parencite[378]{dubois_optimization_2012}. 
While essentially containing the same information,
it does not emphasize the fact that subjects can reencounter the same 
players again and consequently might have influenced the subjects to play
the strategy associated with less risk.

An interesting experimental approach is executed by 
\textcite{dufwenberg_gender_2005}. They tried to evaluate whether 
there is a difference in coordination behavior accross genders, motivated by 
the different treatment of males and females in the work place. Playing the 
weak-link order statistics game of \textcite{van_huyck_tacit_1990}, groups of 
only females or only males face the coordination problem with Pareto-ranked 
equilibria. The motivation of observing gender differences was 
``never explicitly pointed  out to the subjects'' 
\parencite{dufwenberg_gender_2005}\footnote{
Even though it would be interesting to see if there is an effect like 
the discussed ``crab basket'' effect which leads woman to mistrust each other 
more than in a mixed group.}. However, they did not find that the groups play
differently. Differences in the beginning ``disappeared fast and no difference
is found in later stages'' \parencite[235]{dufwenberg_gender_2005}. 
All groups converged to the choice of the minimum
contribution. As they mention, it might be useful to investigate 
coordination of groups that also have some other 
characteristica in common. They refer to the differences group 
identity has for females and males playing a 
public goods game. Namely, \textcite{croson_groups_2008} found that when
females in a sorrority play the public goods games they perform better than 
females with no specific belongingness. Contrarly, males in a fraternity 
performed worse than males without a group identity. 
Interestingly, this and other factors concerning the group of subjects 
playing the coordination game might be a rationale for the 
initial conditions in the evolutionary dynamic. 
The intitial conditions then capture the composition of the subjects 
interacting, reflecting how well trust or cultural conventions 
are embedded in the population. 
Nevertheless, it seems difficult, atleast for the author, to justify
the reduction of the inheritance of cultural values to 
one\footnote{Of course, in games with more than two strategies 
the initial conditions are represented by a vector} dimension such 
as the initial conditions $x_0$.

The discussion of the laboratory research makes on clear: There is more
to the coordination problem than individuals programmed like a robot 
to a strategy, while being attracted and moved to an equilibrium by a 
dynamic in a fully deterministic fashion. But, as a model should, the 
analysis offers a simplification that helps to understand some of the 
patterns observeable when real people interact. 
