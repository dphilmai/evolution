\label{sec:experimentalevidence}
A third approach beside the traditional and the evolutionary treatment of 
coordination problems is what Camerer calls the 
``fundamentally empirical'' approach \parencite[336]{camerer_behavioral_2003}.
Hence, this section consults the experimental economic literature regarding 
laboratory coordination games to provide evidence how actual people choose
their strategies in such situations and which factors might influence them. 
Precisely, do people, if they are able to coordinate on an equilibrium at all,
play the risk-dominant or the payoff-dominant equilibrium? And how does their
choice change, playing the game repeatedly?
Due to the rich experimental literature on coordination in social 
dilemmas, the focus will be on studies with a framework close to the  
evolutionary SH game. A comparison will show the shortcomings and what
is described well by the evolutionary framework.
 
Due to the different notations authors use, a translation into the present
notation was performed.
On these grounds, the 
strategy used in the payoff-dominant equilibrium of the SH game will be 
either called  \textit{strategy S} or in analogy to the stag hunt story 
\textit{hunting stag}.
Consistently, the strategy used in the risk-dominant equilibrium is called
\textit{strategy H} or \textit{hunting hare}.

The papers of \textcite{van_huyck_tacit_1990} and 
\textcite{cooper_communication_1992} are seen as the first experiments 
investigating coordination games \parencite{devetag_when_2007}.
In \textcite{van_huyck_tacit_1990}, subjects do not play a stag
hunt, but an order-statistics game. These games differ in that subjects can
choose from a broader set of strategies, ordered from high to low, and 
hence there are more than two equilibria in the game. 
Played by a group, the players' payoffs depend on the lowest strategy one of 
their group members chose, thus the name 'weak-link' order statistics game. 
Nevertheless, the structure is similar to the stag hunt in the way 
that the equilibria are Pareto-ranked, with one 
safe strategy \parencite{devetag_when_2007}.
So evidence from these games is likely to be transferable to the 
coordination problem in the stag hunt game. 
In \textcite{van_huyck_tacit_1990} subjects played the order-statistics 
game in 
groups of 14-16 for 10 periods. They only received information about their 
payoff, but that was sufficient for the players to find out what the 
lowest choice of one subject in 
their group was. Astonishingly, in every experiment the groups converged
to the equilibrium with the lowest payoff. 
This result was preserved across all groups in another 
five periods of this game, although the subjects played an alternative payoff
matrix, embracing the payoff-efficient equilibrium, in between. 
Replications of these results have been performed numerously, with 
varying group sizes and slightly changed payoff matrices 
\parencite[6]{devetag_when_2007}. 
\textcite{cooper_communication_1992} used a
two-player stag hunt game\footnote{They call 
it simple coordination game (SCG).}  
and one augmented by a dominated strategy. They found that 
subjects in randomly matched one-shot games, knowing only about their own
received payoffs, also failed to coordinate without any preplay communication. 
However, they find that two-way communication, in which both players were
able to send a message to their matched partner containing which strategy
they intend to choose, solves the coordination problem in the SCG. 
In their game, both players had an incentive to truthfully tell their
opponents what they intend to do as ($c=d$). 
Therefore, this does not reject Aumanns hypothesis.
Nevertheless, \textcite{clark_when_2001} run experiments with a game in which
players had an incentive to want their opponents to choose strategy $S$ 
independently of their choice $(c > d)$.
In this game, when both players announced $S$, only 25\% coordinated on
the Pareto-dominant equilibrium. Furthermore, they introduced a game
similar to the typical stag hunt, but with $c<d$. Here, a player saying he 
intends to choose "S" is better off if the other player also chooses $S$, and
so ``communication may be expected to be most credible in Aumann's sense'' 
\parencite[508]{clark_when_2001}. They found that agreements on a strategy
helped to coordinate, but players equally agreed to the Pareto-dominated
equilibrium. 
All in all, preplay communication helps to coordinate, but which
equilibrium is reached depends on the payoff matrix.

However, the 
early approaches by \textcite{cooper_communication_1992} and
\textcite{van_huyck_tacit_1990} suggest that without cheap talk 
coordination failure\footnote{Here in the meaning of not being able to coordinate on the payoff-dominant equilibrium.} 
is common in the laboratory \parencite[2]{devetag_when_2007}. 

\subsection{Variation of the Payoff Matrix}
In the evolutionary games discussed above, a group of players is randomly
matched against each other to play a stag hunt game. For that reason, the
implementation of random matching in a group closely resembles an 
evolutionary game.

Random matching was conducted by \textcite{battalio_optimization_2001}. 
Subjects played three stag hunt games with the typical symmetric pure strategy
equilibrium and the symmetric mixed strategy equilibrium with $(0.8,0.2)^T \in
\Delta$. Figure \ref{fig:payoffbattalio} shows the payoff matrices of the
games noted as $2R, R$ and $0.6R$. The game $2R$ does not satisfy the
condition for the parameters used throughout this text as $c<d$ ($35<40$).
The notation for the games become clear when observing the 
\textit{optimization premium} of the games. While controlling for the basin of 
attraction of the equilibria - the mixed equilibrium is equal in all games -
they want to explore the effect of an increase in the ``premium for playing
a best-response'' \parencite[751]{battalio_optimization_2001}. 
In order to investigate this, they define the optimization premium $r_j(y)$ of 
a game $j$ as the difference in payoffs choosing the pure strategies 
$e_1$ and $e_2$ while expecting the opponent to play a strategy 
$y=(q,1-q)^T \in \Delta$:
\begin{align}
        r_j(y)= \hat{F_j}(e_1,y) - \hat{F_j}(e_2,y) = \delta_j(q-q^*),
\end{align}
with the \textit{optimization premium parameter} $\delta_j$ and the 
probability used in the mixed strategy equilibrium $q^*$. In the notation
of the parametrized SH game the optimization premium paramater is 
$\delta_j = a - c + d - b$. The optimization
premium is only different from zero if a player expects the other player not
to use the mixed Nash equilibrium strategy.

The parameters for the payoff matrices used in this study 
are reported in figure \ref{fig:payoffbattalio}. 
First of all, they find support for their hypothesis that 
subjects coordinate less frequently on the 
payoff-dominant equilibrium in games with a larger optimization premium. 
In game $0.6R$ ($\delta_{0.6R}=50$) two cohorts and in $R$ ($\delta_{R}=25$)
one cohort converged to the payoff-dominant equilibrium. There was no
cohort in the game with the lowest optimization premium parameter, 
$\delta_{2R}= 15$, that coordinated on stag hunting.
The deterministic replicator dynamic does 
not offer a description of this behavior, since convergence to an 
equilibrium only depends on its basins of attraction once the dynamic 
started, which do not differ for the three games. 
While ``all 24 cohorts start in the basin of attraction
of the risk-dominant equilibrium'' 
\parencite[755]{battalio_optimization_2001}, all cohorts 
should converge to the risk-dominant equilibrium according to the dynamic.
But, for the sake of completeness, a crossing of the  
``best-response separatrix'' \parencite{battalio_optimization_2001}, i.e.\ 
mixed-strategy equilibrium, can not happen in the deterministic replicator 
dynamic. Furthermore, as they conjectured, a larger optimization premium 
increases the speed of convergence. Hence, a coordination on a equilibrium 
was achieved fastest in the $2R$ game. This is consistent with a 
postulated replicator dynamic for these games. Starting from 
\eqref{eq:replicator}, one can derive that the dynamics of this 
games are the same up to a change in speed, proportional to the ratio of 
optimization premia of the games. Thus, in game $R$ the change 
in the population share playing strategy $S$ is half the 
speed of $2R$ and four thirds of $0.6R$,
$\dot{x}_{R} = \frac 12 \dot{x}_{2R} = \frac{4}{3}\dot{x}_R$.

\textcite{schmidt_playing_2003} designed their experiment so that the effect
of differing risk levels could be observed. It stands to reason to relabel 
the strategies in the game, because in their treatment the payoff-dominant 
equilibria is in the right corner of the normal form game representation,
contrary to the notation used throughout this text. Comparing risk levels between
games, they used a measure formulated by \textcite{selten_axiomatic_1995}, 
defined
as:
\begin{align}
        \label{riskmeasureschmidt}
        R = ln\left(\frac{\hat{F}(e_2,e_2) -\hat{F}(e_1,e_2)}{\hat{F}(e_1,e_1) 
        -\hat{F}(e_2,e_1)}\right) = ln \left(\frac{d-b}{a-c}\right)
\end{align}
The risk measure $R$ is positive if the Nash equilibrium $(e_2,e_2)$ is
risk-dominant, and negative if the payoff-dominant equilibrium inhibits both
properties. For $R=0$, the mixed strategy equilibrium is risk-dominant.
Risk-dominance of a game compared to another is stronger 
if it has a higher value of $R$.
In contrast to \textcite{battalio_optimization_2001}, they do not
use the proposed optimization premium, but rather measure the 
payoff-dominance level in relative terms 
as $P=\frac{a-d}{a}$.\footnote{As they mention, the 
games in \textcite{battalio_optimization_2001} vary in their level of 
P accordingly.}
The payoff matrices of the games are shown in figure \ref{fig:payoffschmidt}.
Comparing game 2 with game 3, and game 1 with game 4, the games
only differ in their degree of risk-dominance and hence one can 
investigate if subjects react to a change in $R$ ceteris paribus. 
For game 1 and game 3 the basins of attraction of both equilibria is equal as
the Mixed-NE is at $(\frac 12, \frac 12)$ and  for
game 2 and 3 the Mixed-NE is at $(\frac 34,\frac 14)$, resulting in the 
typically larger basin of attraction of the equilibrium $(e_2,e_2)$. 
Therefore, it is expected from the replicator dynamic, of course 
depending on the inital condition 
of the game, that subjects are more likely attracted to the hare hunting 
equilibrium in game 2 and 3. In their implementation of a 
random matching protocol, \textcite{schmidt_playing_2003} 
found evidence that an increase in $R$ leads to a higher choice 
of the strategy in the risk-dominant Nash equilibrium. Players did not react 
to changes in $P$, the level of payoff dominance, but to the changes in $R$.

According to \textcite{rydval_loss_2005}, the risk measure $R$ 
can be interpreted as the risk concerned with a players' 
own deviation from one strategy to another.
\textcite[19]{rydval_loss_2005} suggest "[R]ather than their
own deviation [...], players might worry about their opponent's choices", 
and hence a "definition of risk other than that embedded in the definition
of risk dominance" is necessary.
\textcite[371]{dubois_optimization_2012} 
introduced an alternative measure for risk, named the 
\textit{relative riskiness} of a game, defined as $RR = \frac{|d-c|}{a-b}$.
Intuitively, a player committed to strategy $S$ receives less payoff $(a-b)$  
when his opponent switches from strategy $S$ to $H$. Similar thoughts lead
to a difference of $(c-d)$ for a player committed to strategy $H$. Hence, the
$RR$ is simply the ratio of those payoff differences caused by an opponents
deviation.
Alternatively, it can be interpreted as the ratio of the 
standard deviations of the payoffs 
\parencite[372]{dubois_optimization_2012}. 
The relative riskiness measure is close to one if both strategies involve
similar risk. Accordingly, a lower relative riskiness measure implies that
strategy $H$ has a lower risk compared to strategy $S$.
A game with a lower $RR$ indicates lower relative riskiness of the strategy
$S$ to $H$ compared to another game.
Observing the values of the relative riskiness by 
\textcite{dubois_optimization_2012} and the risk-dominance measure of 
\textcite{schmidt_playing_2003} for the games used in the papers, it is clear
that both measures are in a conflict. As by the measure 
\textcite{schmidt_playing_2003} used, risk-dominance is kept 
constant in the games of  \textcite{battalio_optimization_2001}, 
whereas relative riskiness indicates a variation. 
On the other hand, relative riskiness cannot distinguish between
the games 1,2 and 3 of \textcite{schmidt_playing_2003}, since $RR=0$. In an
early working version of their paper they explicitly excluded the case 
$c \neq d$ and statet that ``a more general measure of relative riskiness 
should allow for the case where c=d as compared to $(a-b)$'' 
\parencite{dubois_optimization_2008}. The distinction between the two
measures can be illustrated by two games. Suppose a game A with the parameters 
$(a,b,c,d) =(9,0,8,7)$ and a game B with $(9,0.5,6.5,6)$. Both games
have the same optimization premium
Game B has a lower risk than A in regard to the relative riskiness
measure as $RR_B=\frac{1}{17} < RR_A =\frac19$. Conversely, the 
risk measure $R$ indicates that risk-dominance is stronger in game A because
$R_A =ln(7) > R_B=ln(2.2)$.

The experimental design of \textcite{dubois_optimization_2012} is similar
to that of \textcite{battalio_optimization_2001}.
Game 1 replicated game $0.6R$  of \textcite{battalio_optimization_2001}  
(Compare figure \ref{fig:payoffdubois} and \ref{fig:payoffbattalio}). 
As per their conjecture, they found that a lower relative riskiness 
in a game decreases the rate at which players choose strategy $S$, 
keeping the optimization premium constant. This is congruent with 
the intuition that the severity of the impact connected to the uncertainty
about an opponents choice, expressed in
the difference in payoffs a deviation of the opponent would cause,
effects a players strategy choice. 
On the other hand, keeping the relative riskiness constant and varying the
optimization premium, they cannot find an effect on the frequency of 
strategy $S$. 
In measuring the ``coordination success'', they deploy the concept of ``strong
coordination'' \textcite{dubois_optimization_2012}. 
In other words, they count the occurrence of periods in which a group
uniformly adopts a strategy so that every pair of subjects lands in one
of the Nash equilibria. \textcite{dubois_optimization_2012} intend to sort 
out ``fortuitous coordination'', coordination as a consequence of subjects being
randomly matched with each other \parencite[373]{dubois_optimization_2012}.
Comparing strong coordination between the games they find a non-significant 
difference between game 1 and game 2 in which only the relative riskiness 
ceteris paribus was changed. Contrary to that, there is a significant 
difference in the commonness in game 3 to game 2.
Since game 3 and 2 only differ in their optimization premia, 
\textcite{dubois_optimization_2012} conclude that a higher optimization
premium leads to more frequent (strong) coordination. 
As they mention, this supports the observation of 
\textcite{battalio_optimization_2001} that coordination success depends 
positively on the optimization premium. 

On the basis of the evidence provided in \textcite{battalio_optimization_2001},
\textcite{schmidt_playing_2003} and \textcite{dubois_optimization_2012},
it seems fair to suggest that the structure of the payoff matrix has a 
strong impact on the way people play the stag hunt game. Additionally, 
the treatment of \textcite{dubois_optimization_2012} suggests that suspects 
not only react to a risk measure that is theoretically derived from the
risk-dominance criterion.
However, the story the evidence tells so far is quite frightening. 
Failure to coordinate on the payoff-dominant equilibrium is apparently common. 

A conflicting result was presented by \textcite{rankin_strategic_2000}.
Following an argument of \textcite{kreps_game_1990} that identical strategic 
interactions, such as the play of completely identical stag hunt games 
in the laboratory, ``take us very little distance outside the laboratory'' 
\parencite[212]{kreps_game_1990}, 
they designed an experiment with a randomly 
pertubed stag hunt game. Essentially, the payoff to strategy $S$ is fixed, 
whereas the payoff to strategy $H$ varies randomly between the games. This is
depicted in the payoff matrix  \eqref{eq:payoffrankin}.
\begin{align}
        \label{eq:payoffrankin}
        A = \mqty(1 & 0 \\ x & x)
\end{align}        
The parameter $x$ is equally distributed between $(0,1)$ and, once a sequence
was calculated, used for all cohorts participating in the experiment. This
variation justifies to describe the games as ``similar'' but not
``identical'', hence the structure stays the same, but the risk-dominance 
property varies. Indeed, if $x$ is greater than $0.5$, risk-dominance and
payoff-dominance select different equilibria, $(e_2,e_2)$ and $(e_1,e_1)$,
respectively. For a value of $x$ smaller than $0.5$ both select 
the equilibrium in strategy $S$. One finds that the optimization premium for 
this randomly perturbed games does not change, since $\delta=1-x+x+0=1$. 
The relative riskiness measure $RR$ cannot discriminate between these games,
since $|d-c|=0\ \forall x$. $R$ is positive for $x > 0.5$ and 
negative for $x <0.5$. The question \textcite{rankin_strategic_2000}
want to investigate is, whether this framework of slightly varied situations may
lead the groups to form a ``convention'' which deductive principle to choose. 
In contrast to the studies performed with identical stag hunt games, they 
observe coordination to the payoff dominant equilibrium across
all cohorts. Whereas in the first ten periods of play risk dominance seems
to have some explanatory power for the choice of strategies, in the last ten
rounds 91\% chose the payoff dominant action. 
In the cases of coinciding equilibrium selection of risk-dominance and 
payoff-dominance ($x < 0.5$), all subjects in group 1-5 
and 95\% of the subjects in group 6 coordinated on that equilibrium.
For the other case a ($x >0.5$) high coordination on the payoff-dominant 
strategy was observed as well.
The hypothesis of an emerging convention based on the deductive principle
payoff-dominance is supported by a frequency of strategy $H$ of 80\% to 95\%.
Contrary to previous experiments, this sends 
quite a positive image about coordination, as this is 
``dramatically at odds with claims that coordination failure is common''
\parencite[9]{devetag_when_2007}. 

A major difference between the evolutionary agents and 
real people are the cognitive abilities.
Certainly, it is to suspect that real players, opposed to the agents
following a simple imitation rule, can take into account what strategies 
were played in the rounds before.
\textcite{battalio_optimization_2001} used a logistic-response model to
investigate if the optimization premium affects the reliance of subjects
on the history of play. Indeed, they found the highest sensitivity of 
individuals to previous rounds in game $2R$.
\textcite{dubois_optimization_2012} confirms this result, also using 
a logistic-response model. Additionally, they cannot reject the null
hypothesis that sensitivity to previous play is significantly different for
game 2 and 1. Hence, they do not find an effect of a change in the
relative riskiness. Interestingly, the logistic-response model can be
formulated as a single-population continuous-time logistic-response dynamic
\parencite[752]{battalio_optimization_2001}. The derivation is due to
\textcite{fudenberg_theory_1998}. Its dynamic properties are different
than that of the replicator dynamic as it does not satisfy payoff monotonicity.
For example in the stag hunt game the dynamic does not have the same inner
fixed point as the replicator dynamic. Instead, the literature speaks
of a logit equilibrium \textcite{battalio_optimization_2001}. The discussion
of the explicit dynamic is beyond the scope of this thesis. 
However, it is interesting to note that revision protocols can be motivated 
that incorporate that agents use the history of play for their future strategy
choice.

\subsection{Details of the Implementation}
As outlined, most studies concerned with the stag hunt game in the 
laboratory focused on the characteristics of the payoff matrix. 
However, details of the implementation,
such as the matching protocol influence behavior sharply. Not only 
\textcite{van_huyck_tacit_1990} found 
convergence to the payoff-dominant equilibrium in their two-player 
fixed matching implementation.  
\textcite{clark_repetition_2001} also found different strategy 
choices between randomly matched one-shot games and fixed matching protocol 
games. The latter lead to significantly higher choices of the strategy 
in the efficient equilibrium and less ``disequilibrium play'' in general
\parencite[]{clark_repetition_2001}. 
\textcite{devetag_when_2007} mention that one-shot games imply a 
random matching protocol. Yet it is different to random matching on group
basis, where subjects can play against the same opponent again 
and hence there is the possibility that a ``convention'' emerges like in 
\textcite{rankin_strategic_2000}.

Even more subtle experiment design differences are conjectured to have an
effect. For example \textcite{devetag_when_2007} suggest that the formulation
``you will remain grouped with the same seven other participants for the next
75 rounds'' in the instruction of the \textcite{rankin_strategic_2000}  
experiment may increased trust within the group and hence was a 
cause for the exceptional coordination success. Comparatively, the 
instructions in \textcite{dubois_optimization_2012} read ``At the beginning
of each period, in each group (composed of 8 participants), the computer
system will form 4 pairs of subjects. [...] The experiment 
involves 75 rounds''\parencite[378]{dubois_optimization_2012}. 
While essentially containing the same information,
it does not emphasize the fact that subjects can encounter the same 
player again and consequently might have influenced the subjects to play
the strategy associated with less risk.

An interesting experimental approach is executed by 
\textcite{dufwenberg_gender_2005}. They tried to evaluate whether 
there is a difference in coordination behavior across genders, motivated by 
the different treatment of males and females in the work place. Playing the 
weak-link order statistics game of \textcite{van_huyck_tacit_1990}, groups of 
only females or only males face the coordination problem with Pareto-ranked 
equilibria. The motivation of observing gender differences was 
``never explicitly pointed  out to the subjects'' 
\parencite{dufwenberg_gender_2005}.
However, they did not find that the groups play
differently. Differences in the beginning ``disappeared fast and no difference
is found in later stages'' \parencite[235]{dufwenberg_gender_2005}. 
All groups converged to the choice of the minimum
contribution. As they mention, it might be useful to investigate 
coordination of groups that also have some other 
characteristics in common. They refer to the differences group 
identity has for females and males playing a 
public goods game. Namely, \textcite{croson_groups_2008} found that 
females in a sorority playing the public goods game perform better than 
females with no specific affiliation. Contrarily, males in a fraternity 
performed worse than males without a group identity. 
Interestingly, this and other factors concerning the group of subjects 
playing the coordination game, might be a rationale for the 
initial conditions in the evolutionary dynamic. If there is no 
``slice of history" available,
the initial conditions could capture the composition of the subjects 
interacting, reflecting how well trust or cultural conventions 
are embedded in this group. It might be interesting to observe the 
coordination of groups where to each subject the composition of the group
was pointed out. For example, I suspect that the behavior of people that
are permanently confronted with risky decisions and the risky decisions
of others, knowing that they are interacting with her kind, 
may not be as sensitive to risk-dominance as people that do not
have this experience.
Nevertheless, it seems difficult, at least for the author, to justify
the reduction of the inheritance of cultural values or conventions to 
one\footnote{Of course, in games with more than two strategies 
the initial conditions are represented by a vector.} dimension such 
as the initial conditions $x_0$.
