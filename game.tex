\documentclass[11pt]{article}
\usepackage{todonotes}
\usepackage{float}
\usepackage[backend=biber,style=authoryear,maxcitenames=2,url=false]{biblatex}
%\bibliography{bibevol2.bib}
\bibliography{bibevol.bib}
%\bibliography{bibevol3.bib}
\bibliography{bibevol4.bib}
\usepackage{sgame}
\input{mathinput.tex}
\pgfplotsset{compat=1.11}
\linespread{1.5}
\newcommand{\natnumb}{\mathbb{N}}
\newcommand{\realnumb}{\mathbb{R}}
\presetkeys{todonotes}{color=yellow,size=\scriptsize}{}
\begin{document}
\section{Introduction}
\begin{figure}[h]
\begin{center}
\begin{game}{2}{2} & $S$ & $H$
\\ $S$ &$a,a$ &$b,c$
\\ $H$ &$c,b$ &$d,d$ \end{game}
\label{sh}
\end{center}
\caption{A parametrized form of the Stag hunt game}
\end{figure}
\section{The Stag hunt game}
\label{sec:traditional}
\todo{Motivation of traditional game theory}
As introduced, the stag hunt game is played by two players who choose their
strategies simultaneoulsy. Both have information about the strategies of the
other player and the payoffs they and their opponents receive. In game theory
such a game is called a \textit{normalform} game. Typically, such a game is
formalized as a Triplet $\Gamma = (I,\mathbb{S},F)$, with the set of players 
$I=\{1,2,...,n\}$, where $n$ is the total number of players, 
the pure strategy space of the game $S = \times_i S_i$
with the pure strategy space $S_i$ of an individual player 
$i \in I$ defined as $S_i = \{1,2,...,m_i\}$, where $m_i$ denotes the total
number of strategies available to player $i$, and the payoff function 
$F: S \rightarrow \realnumb^n$.
As this text focusses on the stag hunt game, which is a normalform game,
this definitons reduce to the following.
By setting $n=2$, we define the two hunters playing SH as $I=\{1,2\}$. A 
player $i \in I$  can choose from a set of pure strategies from his 
pure strategy space, $S_i$. Those strategies are called pure, because they 
differ from the later defined mixed strategies. In the SH game, 
each hunter can choose out of two pure strategies, namely, huntig the stag 
(strategy 1) or hunting hare (strategy 2).
Therefore, the pure strategy space is defined by $S_i = {1,2}$, which results
from definiton ???? by setting $m_i$. In the SH game both players choose from
the same set of stragies such that $S_1 =S_1=S$. Combining the strategy spaces
of the two players with the cartesian product
yields the definiton of the pure strategy space of the game
$\mathbb{S}= S \times S = S^2$.

In SH the hunters do not just hunt for their pleasure \todo{Hunter bewerten 
Ausgang des Spiels}\footnote{Even though the
situation would not differ, aslong as we assume the pleasure hunting a stag
to be higher than hunting hare, since economically payoffs are interpreted as
utility in the theory of households.}, but to seek 
a reward for their loot. This is captured by the definition of an individual
payoff function $F_i:S \rightarrow \realnumb$, which maps for a player $i \in
I$ to every state of the game $s=(s_1,s_2) \in S^2$, where $s_i$ is a 
pure strategy of player $i$, a payoff $F_i(s) \in \realnumb$. So
every outcome of the game, every combination of strategies the players could
individually choose, is defined. In the special case of two player, one 
can define a payoff matrix for player 1 $A \in \realnumb^{2 \times2}$ and for 
player 2  $B \in \realnumb^{2 \times2}$, where $A_{kl} = F_1(k,l)$ and $
B_{kl} = F_2(k,l)$ with the pure strategies $k,l \in S$. Using the 
representation above, one can indentify the payoff matrices for the player as
\begin{align}
        A = \mqty(a && b \\ c && d), \quad B = \mqty(a && c \\ b && d)
        \label{eq:matrix}
\end{align}

In the study of games, one is interested in defining subclasses of games.
For the game here in study the following definition is important: 
\begin{mydef}
        A two player game $\Gamma=(I,S_1 \times S_2, A,B)$ is called symmetric
        if the players of the game have the same strategy space $S_1=S_2=S$ and
        for the payoff matrices the condition $B=A^T$ holds. Therefore, the
        game is well-defined as $\Gamma=(I,S^2,A)$.
        \label{symmetry}
\end{mydef}
Clearly, the SH game is such a game. Both hunters have the same strategies 
available and the payoff matrices defined in \todo{Richtiges Nummerieren der 
Gleichungen} \eqref{eq:matrix} fulfill the required condition in Definition
\ref{symmetry}. Hence, it is irrelevant which player we label 1 or 2.


Usually a game is extended by the possibility of the players to play
\textit{mixed strategies}. Intuitively, in the analogy of SH, one can think of
such strategies as that a hunter decides whether to shoot the stag or the hare
by flipping a coin which shows head or tails, not necessarily with an equal
probabillity.\todo{Interpretation intuitively problematic e.t.c.} Formally, every player of the game assigns a probabillity 
distribution over his pure strategies space.  
A strategy $x_i \in \Delta_i$ of player $i \in I$ 
is called a \textit{mixed strategy}, where $\Delta_i$ is the mixed strategy 
space 
\begin{align*}
        \Delta_i = \{ x_i \in \realnumb^2 : \sum_{k \in S} x_{ik} = 1, x_{ik} \geq 0 \quad
\forall k \in S\}.
\end{align*}
\todo{Geometric Interpretation as a Simplex}
Since there is no restriction for any players choice of the probabillity 
distribution, in a symmetric game the mixed strategy spaces of the players
also equal. For the SH game this means $\Delta_1 = \Delta_2 = \Delta$.
With this notation a pure strategy can be interpreted as a mixed strategy
which assigns probabillity one to the pure strategy chosen and zero to all
other strategies. This is represented by the unit vectors of the simplex 
$\hat{e}_k \in \Delta$, $\hat{e}_1 = (1,0)^T$ is the pure strategy hunting stag 
and $\hat{e}_2 =(0,1)^T$ denots the pure strategy hunting hare.
Similiar to the pure strategy case, the mixed strategy spaces of the players 
$\Delta$ is combined to the mixed strategy space of the game $\Delta^2 =
\Delta \times \Delta$. From now on $x \in \Delta$ denotes a (mixed) strategy
chosen by player 1 and $y \in \Delta$ a (mixed) strategy of player 2.
Again similiar to the pure strategy case, the mixed strategy payoff 
$\hat{F}_i:\Delta^2 \rightarrow \realnumb$ maps to any state in the mixed strategy
space  $(x,y) \in \Delta^2$ a payoff $\hat{F}_i(x,y) \in \realnumb$.
With the matrix notation this is defined as: 
\begin{alignat*}{2}
        \hat{F}_1(x,y) &= x^T A y \\
        \hat{F}_2(x,y) &= x^T A^T y 
\end{alignat*}

Finally, the SH game is formally defined as a symmetric two-player normal form
game $\Gamma = (I=\{1,2\}, \Delta^2, \hat{F})$.

\subsection{Traditional concepts}
In describing the behavior of agents game theory developed a wide range of 
tools to solve this strategic interactions. \todo{Rationality assumption and
Equilibrium knowledge required for Nash equilibrium}

The \textit{best-reply} for player $i \in I$ to a strategy $y \in \Delta$ 
played by $j \neq i$ is defined as:
\begin{align}
        \beta(y) = \{x \in \Delta: \hat{F}(x,y) \geq \hat{F}(x',y), 
        \quad \forall x' \in \Delta\}
\end{align}
This formally assigns to each strategy of the other player the strategies
of player $i$ resulting in the highest payoff for player $i$. However, a player
must be capable of computing his best-reply to a given strategy.

The most famous and used traditional solution concept, the \textit{Nash 
equilibrium} assumes this kind of capability of each individual players. 
The Nash equilibrium was named by its proposer J. Nash in 1950. \todo{Citation
of Nash and history}

A Nash equilibrium for the SH game is defined as
\begin{mydef}
        A state of $(x^*,y^*) \in \Delta^2$ is called a Nash equilibrium if 
        it holds that\todo{Nicer form}
\begin{itemize}
        \item   $(x^*)^T A y^* \geq x^T A y^*, \quad \forall x \in \Delta$
        \item   $(x^*)^T A y^* \geq (x^*)^T A y, \quad \forall y \in \Delta$.
\end{itemize}
It is called symmetric if $x^* = y^*$. It is a strict Nash equilibrium if 
the inequality is strict.
\end{mydef}
It is equivalent to say that both players play best-replies in a Nash 
equilibrium. One can proof that in every normal form games with mixed 
strategies a Nash equilibrium exists. This existence proof is due to Nash\todo{Citation}.

So, the SH game admits three symmetric Nash equilibria. The first one consists
of both players choosing strategy 1, hunting stag, $(\hat{e}_1,\hat{e}_1) \in
\Delta^2$. The second one is the state of 
both players choosing strategy 2, hunting hare, $(\hat{e}_2,\hat{e}_2)
\in \Delta^2$. Additionally to this Nash equilibria in pure strategies, there 
is a mixed strategy equilibrium. 
\todo{Local shifts, associated payoff matrices}
\subsection{Evolutionary concepts}

\subsection{Equilibrium Selection}
Clearly, game theory has the aspiration to provide advise for agents in 
situations such as that defined above.
As seen in the stag hunt game, the mostly used solution concept, 
the Nash equilibrium, and refinements such as the ESS are
not sufficient to select a unique equilibrium, even in the case of a simple
2x2 game. This does not satisfy game theorists since it is not clear which
equilibrium is finally played by the agents. Or how \cite{weibull} puts it,
this kind of coordination games "caused\footnote{And still causes} game theorists and users of 
noncooperative game theory a fair amount of frustration". 

A closer look at the two pure Nash equilibria in the Stag hunt game 
shows their differences. Considering the normal form representation in figure 
\ref{sh}, the Nash equilibrium where both players choose strategy one has the highest payoff
for both players. It is then said that $(\hat{e}_1,\hat{e}_2)$ 
\textit{Pareto-dominates} $(\hat{e}_2,\hat{e}_2)$. In the other standard 
normal form game describing a social-dilemmata, the Prisoners Dilemma, as 
shown in figure \ref{pd} the Pareto-dominant outcome is not a 
Nash equilibrium\footnote{This is true for one-shot games. 
In repeated games there is the possibility in ending at the Pareto efficient 
outcome.}, because every agent has the incentive to deviate. In the stag hunt
game this is not the case. Every agent plays a best-reply in the Pareto efficient
outcome, but since there is another Nash equilibrium it is not clear 
which one is played based on this criterion alone. Based on \cite{schelling}
one may argue that Pareto-dominance characterizes $(\hat{e}_1,\hat{e}_1)$ 
as a focal point of the game, a solution of the game which makes the most sense
to play but the reasons for this are abstracted away from the strategic form and are consens among
the players. \todo{Focal points definition} However, the equilibrium point
$(\hat{e}_2,\hat{e}_2)$ exhibits the feature of \textit{Risk-Dominance}. 
\cite{seltenharsanyigeneral} defined this selection criterion based on the
risk for the players associated with an equilibrium point. Formally, in the
SH game, 
\begin{mydef}
The Nash equilibrium $x=(\hat{e}_2,\hat{e}_2)$ \textit{risk-dominates} 
         the Nash equilibrium $y=(\hat{e}_1,\hat{e}_1)$, if $d-b > a-c$.
         \label{riskdom}
 \end{mydef}\todo{Maybe change this definition}
 As mentioned in \cite{weibull} a NE risk-dominates, if it is Pareto-efficient
 in the reduced payoff version of the game, associated with the diagonal
 payoff matrix in \eqref{diagmatrix}, as the definition \ref{riskdom} 
 corresponds to $\alpha_1 < \alpha_2$.
So both pure Nash equilibria have a certain appeal for game theorists to be
favored. Indeed, there is no clear consent which equilibrium will be played. 
\cite{aumann} argues that communication before the game would lead to 
an agreement on the Pareto-dominant equilibrium.\todo{Cheap talk: Find the paper
Aumann 1990}
Although Harsanyi and Selten introduced the Risk-dominance criterion in 
\cite{seltenharsanyigeneral}, their general theory favors Payoff-dominance in the
Stag hunt case. On the hand, Harsanyi, as Aumann, later advocates in \cite{harsanyinew} 
for the Risk-dominant criterion. 

The evolutionary approach outlined in the next section may contributes to 
the equilibrium selection problem. 

\section{The Evolutionary Game}
\label{evolutionarysection}
Evolutionary game theory, started by Maynard Smith, has find a lot of 
recognition in the game theory literature. \todo{Applications and stuff}

In an evolutionary game, a population of agents interacts in a 
strategic environment. It is usually assumed that the number of agents is 
large, such that an individual agents decision has a small effect on the
state of the population. This is called a \textit{population game} \cite{sandholm_population_2010}.

An evolutionary stag hunt game then consists of agents in a population who
are randomly matched against each other playing the normal form game 
$\Gamma = (I,\Delta^2,\hat{F})$ discussed before. In a \textit{monomorphic}\footnote{In 
contrast to \textit{polymorhpic} populations where each agent can also 
play mixed strategies} setting, the agents are only able to play pure 
strategies. As both settings do not differ in their main implications, 
monomorphic populations admit a handy interpretation for mixed-strategies\todo{Citation, What is Game Theory Trying to accomplish}.
Let $p_j(t) \geq 0$ be the number of individuals playing strategy $j \in \{1,2\}$
at time $t \in \realnumb$ and let $p(t) = p_1(t) + p_2(t)$ describe all individuals 
in the population\footnote{In the model considered here the population will 
not be allowed to grow and hence $p(t) = P \forall t \in \realnumb$}
then $x(t) = \left(x_1(t),x_2(t)\right)=\left(\frac{p_1(t)}{p(t)},\frac{p_2(t)}{p(t)}\right)$ is called the state vector of the population at
time $t \in \realnumb$. The components of the population state vector represent
the share of agents choosing a specific strategy. 
As the individuals can only choose between strategy one and two it holds that 
$x_2(t) = 1-x_1(t)$. Since $x(t) \in \Delta$ \footnote{There is formally no
difference between population state and mixed strategy} a mixed-strategy can 
be interpreted as a population state in a monomorpic population, where the 
population is divided on different strategies. Solving the interpretation
problem for the population setting this interpretation has little relevance
for the standard case. \todo{Cite Interpretation paper}
In the biological literature\cite{maynard} strategies are interpreted as
phenotypes of the population and the payoffs represents the so-called 
\textit{Darwinian fitness} expressing the expected offsprings for the phenotype
in the population. Some animals in the population then die and are replaced
according to the fitness of the phenotype in the current population
state.\todo{Nicer formulation} 
This interpretation is rather unpractical since economic situations rarely
involve the death of their participiants. Therefore, the literature introduces
\textit{Revision Protocols} to model the adjustment of each agents' strategy.
So the agents in this context are not simply replaced by new ones, but rather
change their strategy according to a certain rule. Nevertheless, the
similiarity to biology stays in the manner that the agents are not
assumed to be the \textit{homo rationalis} game theory usually deals with, but
are "programmed" or "wired" \cite{gintis} to their strategy to the revision rule.
\subsection{Revision Protocols}


\subsection{Replicator Dynamics}
The Replicator Dynamic, which is called the "best know dynamic in
evolutionary game theory" by \cite{sandholm_populaton_2010}, has a wide range of applications
and attractive properties. As discussed above, it can be motivated by 
different revision protocols. Formulated for the stag hunt game, one finds for
the strategies $j \in \{1,2\}$
\begin{alignat}{2}
        \dot{x}_j &= x_j\left(\left(x^T A\right)_j - \left(x^T A x\right)\right) 
        \label{replicator}.
\end{alignat}
$x(t)=(x_1(t), x_2(t)) \in \realnumb^2$ is then called a \textit{dynamical
system} defined by the two differential equations in \eqref{replicator}. For
later definitions I will denote the equations as $\dot{x}(t) = f(x(t))$, where
$f(x(t))$ describes the vector field corresponding to the right side of
\eqref{replicator}. \todo{Introduce the notation and terms of a dynamical system}
The growth of the share $\dot{x}_1(t)$ at time $t \in \realnumb$ depends on the current share in the
population of that strategy and the excess payoff $\bar{F}(x(t)) 
= \hat{F}(x,x) = x^T A x$ that strategy earns 
compared to the average payoff of the entire population. Intuitively, the
share of a strategy in the population increases (decreases) if the strategy
yields a higher (lower) than average payoff. This property of a (deterministic)
evolutionary dynamic is called \textit{Positive correlation} \cite{sandholm}.
Another property of the Replicators Dynamics is the low data requirement. As 
seen in the previous section, it is not necessary to assume that an agent
is able to calculate or gets to know the payoffs of all agent in the population.
It was sufficient to assume that he gets to know the payoff of one player. 
As the agents with such revision protocols are often described as boundedly
rational, \cite{gintis} argues that "this is very misleading, because the real 
issue is the distribution of the information". The argument goes, that even
if they were not "bounded" they could not optimize since they do not have
not more information. 
One drawback of the Replicator Dynamic for certain applications, especially
for biologists, is the lack of mutation, a random error in the replication 
process.
\eqref{replicator} shows that the growth of a strategy not present in a 
population state $x(t)$ is zero. So, a population only consisting of agents
playing strategy one stays in that state forever. 

This leads us to the concept of a fixed point. A point $x^* \in \realnumb^2$ of a dynamic system,
such as the replicator dynamic in \eqref{replicator}, is called a fixed point
if $\dot{x}(t) = f(x^*) = 0$ i.e. it stays in the current state for all $t \in 
\realnumb$. 
It is practical for further use to express the replicator dynamics for the
parametrized SH game as 
\begin{align}
        \dot{x} = f(x) = x^2(a-b+2d-2c) - x^3(a-b+d-c) -x(d-c) 
\end{align}
where f(x) is a polynominal of degree $3$. The (real) roots in the 
of this polynominal correspond to the fixed points. 
For the parameter set $a=5, b=3, c=0, d=2$  the graph is plotted in \ref{polynominal}.
Analyzing \eqref{replicator}, this happens if either a strategy
is not present in the population or the excess payoff $\bar{F}(x)$
of a strategy is zero. In the stag hunt game, the fixed points of the
dynamic coincide with the Nash equilibriums of the base game. In general, 
the replicator dynamic lacks the \textit{Nash stationarity} property discussed
in \cite{sandholm}, and hence there are games with fixed points which are not
Nash.\footnote{For a trivial example, consider the prisoners dilemma in 
\ref{prisoners}. A population only consisting of cooperating agents stays in
that state, which is not a Nash equilibrium.} 
Concerning fixed points, a natural question to ask is if they are stable. 
A rather strong requirement is the concept of \textit{asymptotical stability}.
\begin{mydef}
        A state of a differential equation is called asymptotically stable
        if ....
\end{mydef}\todo{Exact definition}
Hence, the system tends to move back to an asymptotical stable fixed point
once disturbed. 
A useful theorem to check for asymptotical stability is that 
of \cite{hartmanngrobman}. \todo{State the theorem of hartmanngrobman}
Applying this theorem to the replicator dynamic of the stag hunt game, we find
\section{A simple model of project coordination}
In unversity, students are faced with assignments and projects, which are 
often performed in groups with fellow students.
Nowadays, most of them involve some kind of 
software tool to either present the results, analyze the subject or just
manage the process of aggretating knowledge. Usually the choice of the tools
can be simplified to two possibilities.
One can either use proprietary software
which is usually more user-friendly or choose to rely on free software which
gains in effectiveness by the open community discussing and solving problems
accordingly. Therefore, proprietary software has clearly the disadvantage of
being expensive, resulting in cost for a license for the student or the
institution using it. 

\section{Experimental Evidence}
A third approach beside the traditional and the evolutionary treatment of coordination problems is what \cite{camerer} calls 'fundamental empirical'.
Hence, this section surveys the experimental economic literature regarding 
laboratory coordination games to provide evidence how actual people choose
their strategies in such situations and which factors might influence them. 
Precisely, do people, if they are able to coordinate on an equilibrium at all,
play the risk-dominant or the payoff-dominant equilibrium? And how does their
choice change playing the game repeatedly?
Due to the rich experimental literature on human decisions in social dilemmetas, I will concentrate on studies with frameworks similiar to the evolutionary stag hunt trying to compare the evidence with the results of the theoretical approaches outlined in previous sections. 
\textcolor{red}{Since the papers I will discuss use different notation and 
label strategies different I find it useful to translate theirs into the
notation I used throughout this text. On these grounds, I will call the 
strategy used in the payoff-dominant equilibrium of the stag hunt game
\textit{strategy 1} or in analogy to the stag hunt story \textit{hunting stag}.
Consistently, the strategy used in the risk-dominant equilibrium is called
\textit{strategy 2} or \textit{hunting hare}. Moreover, I use the notation
introduced in section \ref{sec:traditional} to formulate relevant definitions.}
The papers of \textcite{van_huyck_tacit_1990} and \textcite{cooper_communication_1992} are 
seen as the first experiments investigating coordination games \parencite{devetag_when_2007}.
In \textcite{van_huyck_tacit_1990}, subjects do not play a stag
hunt, but an order-statistics game. These games differ in that subjects choose
from a broader set of strategies and hence there are more than two equilibria
in the game. Also the games are played in a group and the payoff to all 
players depend on the lowest strategy one of them chose, thus the name 
'weak-link' order statistics game. Nevertheless, the structure is similiar to 
the stag hunt in the way that the equilibria are Pareto-ranked, with one 
'safe' strategy \parencite{devetag_when_2007}. So evidence from this games is likely to 
be transferable to the coordination problem in the stag hunt game. In 
\cite{van_huyck_tacit_1990} subjects play the order-statistics game in groups of 
14-16 for 10 periods. They only received information about their payoff, but 
so they could find out what the lowest choice of one subject in their group was.
Astonishingly, in every experiment the groups converged
to the equilibrium with the lowest payoff. This result were preserved in another 
five periods of this game although the subjects played an alternative payoff
matrix embracing the payoff-efficient equilibrium across all groups. 
Replications of this results have been performed numerously, with varying group
sizes and slightly changed payoff matrices. One may consult \textcite{devetag_when_2007}
for a summary. 
\textcite{cooper_communication_1992} perform a experiment with a standard two-player stag
hunt game\footnote{They call it simple coordination game(SCG)} 
and one augmented by a dominated strategy. They find that 
subjects in randomly matched one-shot games, knowing only about their own
received payoffs, coordination also fails without any preplay communication. 
However, they find that two-way communication, in which both players were
able to send a message to their matched partner containing which strategy
they intend to choose, solves the coordination problem in the SCG. 
This early approaces suggest that coordination failure\footnote{Here in the 
meaning of not being able to coordinate on the payoff-dominant equilibrium} is
common in laboratory \parencite{devetag_when_2007}. It is noteworthy that the studies 
discussed used different matching protocols, fixed matching in groups and 
random matching against one other player, and yet found the same results. 
A 'very likely consequence of this' is the focus on characteristics of the
payoff matrix in stag hunt games' rather than the implementational details' 
such as the matching protocol \parencite{devetag_when_2007}.

The implementation of random matching in a group is the closest to the 
evolutionary setting discussed in section \ref{evolutionarysection}. This 
procedure was conducted by \textcite{battalio_optimization_2001}. Subjects 
played three stag hunt games with the typical symmetric pure strategy
equilbrium and the symmetric mixed strategy equilibrium at $(0.8,0.2) \in
\Delta$. Figure \ref{fig:payoffbattalio} show the payoff matrices of the
games $2R, R$ and $0.6R$ used. The names become clear when observing the 
\textit{optimization premium} of the games. While controlling for the basin of 
attraction of the equilibria, i.e. the mixed equilibrium is equal across all games,
they want to explore the effect of an increase in the "premium for playing
a best-response" \parencite[751]{battalio_optimization_2001}. 
\begin{figure}[h]
        \label{fig:payoffbattalio}
\caption{Payoff matrices of games in \textcite{battalio_optimization_2001}}
\begin{alignat*}{3}
        A_{2R} &= \mqty(45 & 0 \\ 35 & 40) \quad & &A_{R} = \mqty(45 & 0 \\ 
        40 & 20) \quad & &A_{0.6R} = \mqty( 45 & 0 \\ 42 & 12) \\
        \delta_{2R} &= 50  \quad & &\ \delta_{R} = 25 \quad & &\ \delta_{0.6R} = 15
\end{alignat*}
\end{figure}
Therefore they define the optimization premium $r(y)$ of a game $j$ as the 
differece in payoffs choosing the pure strategies $e_1$ and $e_2$ 
while expecting the opponent to play a strategy $y=(q,1-q) \in \Delta$:
\begin{align}
        r_j(y)= \hat{F_j}(e_1,y) - \hat{F_j}(e_2,y) = \delta_j(q-q^*),
\end{align}
with the \textit{optimization premium parameter} $\delta_j$. In the notation
parametrized stag hunt game $\delta_j = a - c + d - b$.
The parameters for the payoff matrices are reported in figure \ref{fig:payoffbattalio}. 
First of all, they find support for their hyptohesis that in games with a 
larger optimization premium subjects coordinated less frequently on the 
payoff-dominant equilibrium. 
Contrary to game $0.6R$, where only one cohort coordinated on the risk-
dominant, in $2R$ no cohort and in $R$ only one cohort converged to the 
payoff-dominant equilibrium. The replicator dynamic does not offer a
a description of this behavior, since convergence to a equilibrium only 
depends on its basin of attractions, which do not differ for the three games, 
and the initial conditions. Whereas "all 24 cohorts start in the basin of attraction
of the risk-dominant equilibrium" \parencite{battalio_optimization_2001}, 
all should converge to the risk-dominant equilibrium according to the dynamic.
In the most cases this is true, with only three exception in game $0.6R$ 
and two in $R$.
But, for the sake of completness, a crossing of the  
"best-response separatrix" \parencite{battalio_optimization_2001} i.e. 
mixed-strategy equilibrium, can not happen in the deterministic replicator 
dynamic.
Furthermore, as they conjectured, a larger
optimization premium increases the speed of convergence. Hence, a coordination
on a equilibrium was achieved fastest in the $2R$ game. 
This is consistend with a postulated replicator dynamic for this games. 
Starting from \ref{replicator}, one can derive that the dynamics of this games
are the same up to a change in speed, proportional to the ratio of 
optimization premia of the games. In game $R$ the change in the population share
playing strategy one is, thus, half the speed of $2R$ and four thirds of $0.6R$,
$\dot{x}_{R} = 0.5 \dot{x}_{2R} = \frac{4}{3}\dot{x}_R$.
\textcite{schmidt_playing_2003} designed their experiment such that the effect
of differing risk levels could be observed. It is convenient to relabel 
the strategies in the game, because in their treatment the payoff-dominant 
equilibria is in the right corner of the normal form game representation,
contrary the notation used throuhout this text. Comparing risk levels between
games, they used a measure due to \cite{Seltenanaxiomaticriskmeasure}, defined
as:
\begin{align}
        \label{riskmeasureschmidt}
        R = ln\left(\frac{\hat{F}(e_2,e_2) -\hat{F}(e_2,e_1)}{\hat{F}(e_1,e_1) 
        -\hat{F}(e_2,e_1)}\right) = ln \left(\frac{d-b}{a-c}\right)
\end{align}
The risk measure $R$ is positive, if the Nash equilibrium $(e_2,e_2)$ is
risk-dominant, and negative if the payoff-dominant equilibrium inhibits both
properties.
None of the four games in \textcite{schmidt_playing_2003} handles
the case of $R=0$, where the mixed-strategy equilibrium is risk-dominant.
In difference to \textcite{battalio_optimization_2001}, they do not
use the proposed optimization premium, but rather measure the risk-dominance 
level in relative terms as $P=\frac{a-d}{a}$.\footnote{As they mention, the 
games in \textcite{battalio_optimization_2001} vary in their level of 
P accordingly.}
The payoff matrices of the games are shown in \ref{fig:payoffschmidt}.
Comparing Game 2 with Game 3, and Game 1 with Game 4, the only difference is the 
degree of risk-dominance and hence one can investigate if subjects react 
to the change in risk-dominance. For game 1 and game 3 the basin of attraction
of both equilibria is equal (Mixed-NE at $(\frac 12, \frac 12)$) and  for
game 2,3 the Mixed-NE is at $(\frac 34,\frac 14)$ resulting in the typical 
larger basin of attraction of the strategy $(e_2,e_2)$. So one would expect
from the replicator dynamic, of course depending on the inital condition 
of the game one, to be more likely attracted to the 'hare-hunting' equilibrium
in game 2,3.
\textcite{schmidt_playing_2003} implement three different types of matching
protocol. First of all, a random matching protocol where each subjects is not
matched twice with another person and only has information about his payoff and
the action of the person he was matched against. 
Secondly, a fixed protocol, matching two persons for several rounds against 
each other, followed by a series of one-shot games. 
In the random matching protcol, they find evidence that an increase in 
risk-dominance, i.e. an increase in $R$, leads to a higher choice of the
strategy in the risk-dominant NE.\todo{Schmidt et al paper.} 

\textcite{dubois_optimization_2012} conduct a similiar experiment as 
\textcite{schmidt_playing_2003} and \textcite{battalio_optimization_2001},
but introduce a different measure for the risk subjects are confronted with in
the games. They define the \textit{relative riskiness} of a games 
"safe strategy relative to the risky strategy" as $RR = \frac{|c-d|}{a-b}$.
Intuitively, a player commited to strategy one and calculating the 
difference a deviation of the other player from strategy one to two, gets
$(a-b)$. Similiary for strategy two, he receives $c-d$. The relative riskiness
measure is, hence, the ratio of those deviation calculations. Alternatively,
it can be interpreted as the ratio of the standard deviations of the payoffs 
\parencite{dubois_optimization_2012}. They speak of "comparable riskiness",
if the $RR$ measure is close to one \cite{dubois_optimization_2012}. 
According to $RR$, the risk-dominant strategy 2 is said to be less risky 
relative to the payoff-dominant strategy 1 in on game compared to another if 
$RR$ is smaller.
Observing the values of the relative riskiness by 
\textcite{dubois_optimization_2012} and the risk-dominance measure of 
\textcite{schmidt_playing_2003} for the games used in the papers, it is clear
that both measures are in a conflict. As by \textcite{schmidt_playing_2003}
measure, risk-dominance is kept constant in the games of 
\textcite{battalio_optimization_2001}, relative riskiness indicates a 
variation. On the other hand, relative riskiness cannot distinguish between
the games 1,2 and 3 of \textcite{schmidt_playing_2003}, since $RR=0$. In an
early working version of their paper they explicitly excluded the case 
$c \neq d$ and statet that "a more general measure of relative riskiness 
should allow for the case where c=d as compared to $(a-b)$ 
\parencite{dubois_optimization_2008_working}. 
\todo{Maybe both measures capture different things: Intuition}
With the implementation of game 1 a replication of the results for 
\textcite{battalio_optimization_2001}'s game $0.6R$ could be 
performed\footnote{The payoff matrices are identical. 
Compare \ref{fig:payoffdubois} and \ref{fig:payoffbattalio}}. 
As per their conjecture they found that a lower relative riskiness in a game 
decreased the rate of choice of strategy one, keeping the optimization premium 
constant. This is congruent with the intuition that the severity of the impact 
related with the strategic uncertainty subjects face in a game, expressed in
the difference in payoff a deviation of the other player would cause,
effects the choice of the strategy. 
On the other hand, keeping the relative riskiness constant and varying the
optimization premium, they cannot find an effect on the frequency of 
strategy 1. 
In measuring the "coordination sucess", they deploy the concept of "strong
coordination". 
In other words, counting the occurence of periods in which a group
uniformly adopts a strategy such that every pair of subjects lands in one
of the Nash equilibria. \textcite{dubois_optimization_2012} intend to sort 
out "furtuitous coordination", coordination as consequence of subjects being
randomly matched with each other. Comparing strong coordinations between the
games they find a non-significant difference between game 1 and game 2 in 
which only the relative riskiness certeris paribus was changed. Contrary to 
that there is a significant difference in the commoness in game 3 to game 2.
Since game 3 and game 2 only differ in their optimization premium 
\textcite{dubois_optimization_2012} conclude that a higher optimization
premium leads to more (strong) coordination. As they mention, this agrees
with the observation of \textcite{battalio_optimization_2001} that the 
speed of convergence hinge positively on the optimization premium. \todo{
Is it really the convergence or did I miss something?}
\todo{History of Play}

As seen from the evidence \textcite{battalio_optimization_2001},
\textcite{schmidt_playing_2003} and \textcite{dubois_optimization_2012} 
found, the structure of the payoff matrix has a strong impact on the way 
people play the stag hunt game.   
The story this evidence tells is quite frightening. Failure to coordinate 
on the payoff-dominant equilibrium seems to be common. Following an argument
of \textcite{kreps_game_1990} that identical strategic interactions, such
as the play of completely indentical stag hunt games in the laboratory,
"take us very little distance outside the laboratory", 
\textcite{rankin_strategic_2000} design an experiment with a randomly 
pertubated stag hunt game. Essentially, the payoff to strategy 1 is fixed 
whereas the payoff to strategy 2 varies randomly between the games. This is
depicted in the payoff matrix \eqref{eq:payoffrankin}.
\begin{align}
        \label{eq:payoffrankin}
        A = \mqty(1 & 0 \\ x & x)
\end{align}        
The parameter $x$ is equally distributed between $(0,1)$ and once a sequence
was calculated used for all cohorts participating in the experiment. This
variation justifies to describe the games as "similiar" but not
"identical", hence the structure stays the same, but the risk-dominance 
property varies. Indeed, if $x$ is greater than $0.5$ risk-dominance and
payoff-dominance select different equilibria, $(e_2,e_2)$ and $(e_1,e_1)$,
respectively. For a value of $x$ smaller than $0.5$ both select the 
the equilibrium in strategy 1. One finds that the optimization premium for 
this randomly perturbed games does not change, since $\delta=1-x+x+0=1$. 
The relative riskiness measure $RR$ cannot discriminate between this games,
since $|d-c|=0\ \forall x$. \cite{schmidt_playing_2003} measure of risk of 
course is positive for $x > 0.5$ and negative for $x <0.5$
The question \textcite{rankin_strategic_2000}
want to investigate is, if this framework of sligthly varied situations may
lead the groups to form a "convention" which deductive principle to choose. 
In contrast to the studies performed with identical stag hunt games, they 
observe emerging coordination to the payoff dominant equilibrium across
all cohorts. Whereas in the first ten periods of play risk dominance seems
to have some explanatory power for the choice of strategy, in the last ten
rounds 91\% choose the payoff dominant action. 
In the cases of coinciding equilibrium selection of risk-dominance and payoff-
dominance ($x < 0.5$) all subjects coordinated on that equilibrium in group
1-5 and 95\% of the subjects in group 6. But also for the other case a high
coordination on the payoff-dominant strategy was observed, ranging from 
80\% to 95\% of the strategies played, suggesting that there is clear evidence
for the hypothesis of an emerging convention based on the deductive principle
payoff-dominance. This sends a quite positive image about coordination, because 
this is "dramatically at odds with claims that coordination failure is common"
\parencite[9]{devetag_when_2007}. 
As outlined, the most studies concerned with the stag hunt game in the 
laboratory focused on the payoff matrix. However, implementational details 
such as the matching protocol influence behaviour sharply. Not only 
\textcite{vanhuyck_strategic_1991} found in their two-player fixed matching
convergence to the payoff-dominant equilibrium, 
\textcite{clark_repetition_2001} also found different strategy 
choices between randomly matched one-shot games and fixed matching protocol 
games. The latter lead to significantly higher choices of the strategy 
in the efficient equilibrium and less "disequilibrium play" in general. 

Even more subtle experiment design differences are conjectured to have an
effect. For example \textcite{devetag_when_2007} suggest that the formulation
"you will remain grouped with the same seven other participants for the next
75 rounds" in the instruction of the \textcite{rankin_strategic_2000} 
        experiment may increae trust of the group members and hence be a 
cause for the exceptional coordination success.






\section{Conclusion}
\section{appendix}
\begin{figure}[H]
\label{fig:payoffschmidt}
\caption{Payoff matrices of the games used in \cite{schmidt_playing_2003}}
\begin{alignat*}{3}
        A_{Game1} = \mqty( 100 & 20 \\ 60 & 60), \quad A_{Game2} 
                               &= \mqty( 100 & 20 \\ 80 & 80), \\ 
        A_{Game3} = \mqty( 100 
             & 60 \\ 80 & 80), \quad A_{Game4} &= \mqty( 100
                             & 0 \\ 80 & 60)
        \end{alignat*}
\end{figure}
\begin{figure}[H]
        \caption{Payoff matrices of the games used
        in \cite{dubois_optimization_2012}}
        \label{fig:payoffdubois}
        \begin{alignat*}{3}     
                A_{Game1} &= \mqty(45 & 0 \\ 42 & 12),
                A_{Game2} &= \mqty(40 & 20 \\37 & 32),
                A_{Game3} &= \mqty(44 & 4 \\ 38 & 28) \\
                RR_{Game1}&= \frac 23, RR_{Game2}&=\frac 14, RR_{Game3}&=
                \frac 14
        \end{alignat*}
\end{figure}
\printbibliography
\end{document}







