\documentclass[12pt]{article}
\usepackage{todonotes}
\usepackage{biblatex}
\bibliography{bibevol.bib}
\usepackage{sgame}
\input{mathinput.tex}
\pgfplotsset{compat=1.11}
\linespread{1.5}
\newcommand{\natnumb}{\mathbb{N}}
\newcommand{\realnumb}{\mathbb{R}}
\presetkeys{todonotes}{color=yellow,size=\scriptsize}{}
\begin{document}
\section{Introduction}
\begin{figure}[h]
\begin{center}
\begin{game}{2}{2} & $S$ & $H$
\\ $S$ &$a,a$ &$b,c$
\\ $H$ &$c,b$ &$d,d$ \end{game}
\label{sh}
\end{center}
\caption{A parametrized form of the Stag hunt game}
\end{figure}
\section{The Stag hunt game}
\todo{Motivation of traditional game theory}
As introduced, the stag hunt game is played by two players who choose their
strategies simultaneoulsy. Both have information about the strategies of the
other player and the payoffs they and their opponents receive. In game theory
such a game is called a \textit{normalform} game. Typically, such a game is
formalized as a Triplet $\Gamma = (I,\mathbb{S},F)$, with the set of players 
$I=\{1,2,...,n\}$, where $n$ is the total number of players, 
the pure strategy space of the game $S = \times_i S_i$
with the pure strategy space $S_i$ of an individual player 
$i \in I$ defined as $S_i = \{1,2,...,m_i\}$, where $m_i$ denotes the total
number of strategies available to player $i$, and the payoff function 
$F: S \rightarrow \realnumb^n$.
As this text focusses on the stag hunt game, which is a normalform game,
this definitons reduce to the following.
By setting $n=2$, we define the two hunters playing SH as $I=\{1,2\}$. A 
player $i \in I$  can choose from a set of pure strategies from his 
pure strategy space, $S_i$. Those strategies are called pure, because they 
differ from the later defined mixed strategies. In the SH game, 
each hunter can choose out of two pure strategies, namely, huntig the stag 
(strategy 1) or hunting hare (strategy 2).
Therefore, the pure strategy space is defined by $S_i = {1,2}$, which results
from definiton ???? by setting $m_i$. In the SH game both players choose from
the same set of stragies such that $S_1 =S_1=S$. Combining the strategy spaces
of the two players with the cartesian product
yields the definiton of the pure strategy space of the game
$\mathbb{S}= S \times S = S^2$.

In SH the hunters do not just hunt for their pleasure \todo{Hunter bewerten 
Ausgang des Spiels}\footnote{Even though the
situation would not differ, aslong as we assume the pleasure hunting a stag
to be higher than hunting hare, since economically payoffs are interpreted as
utility in the theory of households.}, but to seek 
a reward for their loot. This is captured by the definition of an individual
payoff function $F_i:S \rightarrow \realnumb$, which maps for a player $i \in
I$ to every state of the game $s=(s_1,s_2) \in S^2$, where $s_i$ is a 
pure strategy of player $i$, a payoff $F_i(s) \in \realnumb$. So
every outcome of the game, every combination of strategies the players could
individually choose, is defined. In the special case of two player, one 
can define a payoff matrix for player 1 $A \in \realnumb^{2 \times2}$ and for 
player 2  $B \in \realnumb^{2 \times2}$, where $A_{kl} = F_1(k,l)$ and $
B_{kl} = F_2(k,l)$ with the pure strategies $k,l \in S$. Using the 
representation above, one can indentify the payoff matrices for the player as
\begin{align}
        A = \mqty(a && b \\ c && d), \quad B = \mqty(a && c \\ b && d)
        \label{eq:matrix}
\end{align}

In the study of games, one is interested in defining subclasses of games.
For the game here in study the following definition is important: 
\begin{mydef}
        A two player game $\Gamma=(I,S_1 \times S_2, A,B)$ is called symmetric
        if the players of the game have the same strategy space $S_1=S_2=S$ and
        for the payoff matrices the condition $B=A^T$ holds. Therefore, the
        game is well-defined as $\Gamma=(I,S^2,A)$.
        \label{symmetry}
\end{mydef}
Clearly, the SH game is such a game. Both hunters have the same strategies 
available and the payoff matrices defined in \todo{Richtiges Nummerieren der 
Gleichungen} \eqref{eq:matrix} fulfill the required condition in Definition
\ref{symmetry}. Hence, it is irrelevant which player we label 1 or 2.


Usually a game is extended by the possibility of the players to play
\textit{mixed strategies}. Intuitively, in the analogy of SH, one can think of
such strategies as that a hunter decides whether to shoot the stag or the hare
by flipping a coin which shows head or tails, not necessarily with an equal
probabillity. Formally, every player of the game assigns a probabillity 
distribution over his pure strategies space.  
A strategy $x_i \in \Delta_i$ of player $i \in I$ 
is called a \textit{mixed strategy}, where $\Delta_i$ is the mixed strategy 
space 
\begin{align*}
        $\Delta_i = \{ x_i \in \realnumb^2 : \sum_{k \in S} x_{ik} = 1, x_{ik} \geq 0 \quad
\forall k \in S\}.
\end{align*}
\todo{Geometric Interpretation as a Simplex}
Since there is no restriction for any players choice of the probabillity 
distribution, in a symmetric game the mixed strategy spaces of the players
also equal. For the SH game this means $\Delta_1 = \Delta_2 = \Delta$.
With this notation a pure strategy can be interpreted as a mixed strategy
which assigns probabillity one to the pure strategy choosen and zero to all
other strategies. This is represented by the unit vectors of the simplex 
$\hat{e}_k \in \Delta$, $\hat{e}_1 = (1,0)^T$ is the pure strategy hunting stag 
and $\hat{e}_2 =(0,1)^T$ denots the pure strategy hunting hare.
Similiar to the pure strategy case, the mixed strategy spaces of the players 
$\Delta$ is combined to the mixed strategy space of the game $\Delta^2 =
\Delta \times \Delta$. From now on $x \in \Delta$ denotes a (mixed) strategy
chosen by player 1 and $y \in \Delta$ a (mixed) strategy of player 2.
Again similiar to the pure strategy case, the mixed strategy payoff 
$\hat{F}_i:\Delta^2 \rightarrow \realnumb$ maps to any state in the mixed strategy
space  $(x,y) \in \Delta^2$ a payoff $\hat{F}_i(x,y) \in \realnumb$.
With the matrix notation this is defined as: 
\begin{alignat*}{2}
        \hat{F}_1(x,y) &= x^T A y \\
        \hat{F}_2(x,y) &= x^T A^T y 
\end{alignat*}

Finally, the SH game is formally defined as a symmetric two-player normal form
game $\Gamma = (I=\{1,2\}, \Delta^2, \hat{F})$.

\subsection{Traditional concepts}
In describing the behavior of agents game theory developed a wide range of 
tools to solve this strategic interactions. \todo{Rationality assumption and
Equilibrium knowledge required for Nash equilibrium}

The \textit{best-reply} for player $i \in I$ to a strategy $y \in \Delta$ 
played by $j \neq i$ is defined as:
\begin{align}
        \beta(y) = \{x \in \Delta: \hat{F}(x,y) \geq \hat{F}(x',y), 
        \quad \forall x' \in \Delta\}
\end{align}
This formally assigns to each strategy of the other player the strategies
of player $i$ resulting in the highest payoff for player $i$. However, a player
must be capable of computing his best-reply to a given strategy.

The most famous and used traditional solution concept, the \textit{Nash 
equilibrium} assumes this kind of capability of each individual players. 
The Nash equilibrium was named by its proposer J. Nash in 1950. \todo{Citation
of Nash and history}

A Nash equilibrium for the SH game is defined as
\begin{mydef}
        A state of $(x^*,y^*) \in \Delta^2$ is called a Nash equilibrium if 
        it holds that\todo{Nicer form}
\begin{itemize}
        \item   $(x^*)^T A y^* \geq x^T A y^*, \quad \forall x \in \Delta$
        \item   $(x^*)^T A y^* \geq (x^*)^T A y, \quad \forall y \in \Delta$.
\end{itemize}
It is called symmetric if $x^* = y^*$. It is a strict Nash equilibrium if 
the inequality is strict.
\end{mydef}
It is equivalent to say that both players play best-replies in a Nash 
equilibrium. One can proof that in every normal form games with mixed 
strategies a Nash equilibrium exists. This existence proof is due to Nash\todo{Citation}.

So, the SH game admits three symmetric Nash equilibria. The first one consists
of both players choosing strategy 1, hunting stag, $(\hat{e}_1,\hat{e}_1) \in
\Delta^2$. The second one is the state of 
both players choosing strategy 2, hunting hare, $(\hat{e}_2,\hat{e}_2)
\in \Delta^2$. Additionally to this Nash equilibria in pure strategies, there 
is a mixed strategy equilibrium. 
\todo{Local shifts, associated payoff matrices}
\subsection{Evolutionary concepts}

\subsection{Equilibrium Selection}
Clearly, game theory has the aspiration to provide advise for agents in 
situations such as that defined above.
As seen in the stag hunt game, the mostly used solution concept, 
the Nash equilibrium, and refinements such as the ESS are
not sufficient to select a unique equilibrium, even in the case of a simple
2x2 game. This does not satisfy game theorists since it is not clear which
equilibrium is finally played by the agents. Or how \cite{weibull} puts it,
this kind of coordination games "caused\footnote{And still cause} game theorists and users of 
noncooperative game theory a fair amount of frustration". 

A closer look at the two pure Nash equilibria in the Stag hunt game 
shows their differences. Considering the normal form representation in figure 
\ref{sh}, the Nash equilibrium where both players choose strategy one has the highest payoff
for both players. It is then said that $(\hat{e}_1,\hat{e}_2)$ 
\textit{Pareto-dominates} $(\hat{e}_2,\hat{e}_2)$. In the other standard 
normal form game describing a social-dilemmata, the Prisoners Dilemma, as 
shown in figure \ref{pd} the Pareto-dominant outcome is not a 
Nash equilibrium\footnote{This is true for one-shot games. 
In repeated games there is the possibility in ending at the Pareto efficient 
outcome.}, because every agent has the incentive to deviate. In the stag hunt
game this is not the case. Every agent plays a best-reply in the Pareto efficient
outcome, but since there is another Nash equilibrium it is not clear 
which one is played based on this criterion alone. Based on \cite{schelling}
one may argue that Pareto-dominance characterizes $(\hat{e}_1,\hat{e}_1)$ 
as a focal point of the game, a solution of the game which makes the most sense to play but the reasons for this are abstracted away from the strategic form and are consens among
the players. \todo{Focal points definition} However, the equilibrium point
$(\hat{e}_2,\hat{e}_2)$ exhibits the feature of \textit{Risk-Dominance}. 
\cite{seltenharsanyigeneral} defined this selection criterion based on the
risk for the players associated with an equilibrium point. Formally, this is
defined as 
\begin{mydef}
         The Nash equilibrium $x=(\hat{e_2},\hat{e_2})$ \textit{risk-dominates} 
         the Nash equilibrium $y=(\hat{e}_1,\hat{e}_1)$, if $d-b > a-c$.
         \label{riskdom}
 \end{mydef}\todo{Maybe change this definition}
 As mentioned in \cite{weibull} a NE risk-dominates, if it is Pareto-efficient
 in the reduced payoff version of the game, associated with the diagonal
 payoff matrix in \eqref{diagmatrix}, as the definition \ref{riskdom} 
 corresponds to $\alpha_1 < \alpha_2$.
So both pure Nash equilibria have a certain appeal for game theorists to be
favoured. Indeed, there is no clear consent which equilibrium is favored. 
\cite{Whatever} argues that communication before the game would lead to 
an agreement on the Pareto-dominant equilibrium.\todo{Cheap talk}
Although Harsanyi and Selten introduced the Risk-dominance criterion in 
\cite{seltenharsanyigeneral}, their theory favors Payoff-dominance in the
Stag hunt case. On the hand, Harsanyi, as Aumann later advocates in \cite{harsanyinew} 
for the Risk-dominant criterion. 

The evolutionary approach outlined in the next section may contributes to 
the equilibrium selection problem. 

\section{The Evolutionary Game}
Evolutionary game theory, started by Maynard Smith, has find a lot of 
recognition in the game theory literature. \todo{Applications and stuff}

In an evolutionary game, a population of agents interacts in a 
strategic environment. It is usually assumed that the number of agents is 
large, such that an individual agents decision has a small effect on the
state of the population. This is called a \textit{population game} \cite{sandholm}.

An evolutionary stag hunt game then consists of agents in a population who
are randomly matched against each other playing the normal form game 
$\Gamma = (I,\Delta^2,\hat{F})$ discussed before. In a \textit{monomorphic}\footnote{In 
contrast to \textit{polymorhpic} populations where each agent can also 
play mixed strategies} setting, the agents are only able to play pure 
strategies. As both settings do not differ in their main implications, 
monomorphic populations admit a handy interpretation for mixed-strategies\todo{Citation, What is Game Theory Trying to accomplish}.
Let $p_j(t) \geq 0$ be the number of individuals playing strategy $j \in \{1,2\}$
at time $t \in \realnumb$ and let $p(t) = p_1(t) + p_2(t)$ describe all individuals 
in the population\footnote{In the model considered here the population will 
not be allowed to grow and hence $p(t) = P \forall t \in \realnumb$}
then $x(t) = \left(x_1(t),x_2(t)\right)=\left(\frac{p_1(t)}{p(t)},\frac{p_2(t)}{p(t)}\right)$ is called the state vector of the population at
time $t \in \realnumb$. The components of the population state vector represent
the share of agents choosing a specific strategy. 
As the individuals can only choose between strategy one and two it holds that 
$x_2(t) = 1-x_1(t)$. Since the population state is formally not different from
a mixed-strategy, $x(t) \in \Delta$, a mixed-strategy can be interpreted as a
population state in a monomorpic population. 
In the biological literature\cite{maynard} strategies are interpreted as
phenotypes of the population and the payoffs represents the so-called 
\texit{Darwinian fitness} expressing the expected offsprings for the phenotype
in the population. Some animals in the population then die and are replaced
according to the fitness of the phenotype in the current population
state.\todo{Nicer formulation} 
This interpretation is rather unpractical since economic situations rarely
involve the death of their participiants. Therefore, the literature introduces
\texit{Revision Protocols} to model the adjustment of each agents' strategy.
So the agents in this context are not simply replaced by new ones, but rather
change their strategy according to a certain rule. Nevertheless, the
similiarity to the biological stays in the manner that the agents are not
assumed to be the \textit{homo rationalis} game theory usually deals with, but
are "programmed", how some authors put it, to the revision rule.
\subsection{Revision Protocols}


\subsection{Replicator Dynamics}
The Replicator Dynamic, which is called the "best know dynamic in
evolutionary game theory" by \cite{Sandholm}, has a wide range of applications
and attractive properties. As discussed above, it can be motivated by 
different revision protocols. Formulated for the stag hunt game, one finds
\begin{alignat}{2}
        \dot{x}_1 = x_1\left(\left(x^T A\right)_i - \left(x^T A x\right)\right)
        \label{replicator}
\end{alignat}
and the condition $x_2(t) = 1-x_1(t)$. The growth of the share
$\dot{x}_1(t)$ at time $t \in \realnumb$ depends on the current share in the
population of that strategy and the excess payoff $\bar{F}(x(t)) 
= \hat{F}(x,x) = x^T A x$ that strategy earns 
compared to the average payoff of the entire population. Intuitively, the
share of a strategy in the population increases (decreases) if the strategy
yields a higher (lower) than average payoff. This property of a (deterministic)
evolutionary dynamic is called \textit{Positive correlation} \cite{sandholm}.
Another property of the Replicators Dynamics is the low data requirement. As 
seen in the previous section, it is not necessary to assume that an agent
is able to calculate or gets to know the payoffs of all agent in the population.
It was sufficient to assume that he gets to know the payoff of one player. 
One drawback of the Replicator Dynamic for certain applications, especially
for biologists, is the lack of mutation. Mutation \todo{Definition of mutation}
\eqref{replicator} shows that the growth of a strategy not present in a 
population state $x(t)$ is zero. So, a population only consisting of agents
playing strategy one stays in that state forever. 
This leads us to the concept of a fixed point. A point of a dynamic system,
such as the replicator dynamic in \eqref{replicator}, is called a fixed point
if $\dot{x}(t) = 0$ i.e. it stays in the current state for all $t \in 
\realnumb$. Analyzing \eqref{replicator}, this happens if either a strategy
is not present in the population or the excess payoff $\bar{F}(x)$
of a strategy is zero. In the stag hunt game, the fixed points of the
dynamic coincide with the Nash equilibriums of the base game. In general, 
the replicator dynamic lacks the \textit{Nash stationarity} property discussed
in \cite{sandholm}, and hence there are games with rest points which are not
Nash.\footnote{For a trivial example, consider the prisoners dilemma in 
\ref{prisoners}. A population only consisting of cooperating agents stays in
that state, which is not a Nash equilibrium.} 
A natural question concerning fixed point is to ask whether they are stable
or if the system tends to move away once it is disturbed. I here consider the
concept of \textit{asymptotical stability}.
\begin{mydef}
        A state of a differential equation is called asymptotically stable
        if ....
\end{mydef}\todo{Exact definition}
One way to show asymptotical stability for rest points is by using the
theorem of \cite{hartmanngrobman}. \todo{State the theorem of hartmanngrobman}




\section{Conclusion}
\printbibliography
\end{document}







