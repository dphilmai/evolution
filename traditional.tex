\label{sec:traditional}
As already explained, the stag hunt game is played by 
two players who choose their
strategies simultaneously.
Both have information about the strategies of the
other player and the payoffs they and their opponents receive. In game theory
such a game is called a \textit{normal form} game with complete information. 
Typically, such a game is formalized as a Triplet $\Gamma = (I,\mathbb{S},F)$, 
with the set of players $I=\{1,2,...,n\}$, where $n \in \mathbb{N}$ is the 
total number of players. 
Expressing all possible states of the game, the pure
strategy space of the game $\mathbb{S}$ is defined as the cartesian
product of the individual pure strategy spaces $S_i$ for a player $i \in I$,
$\mathbb{S}=\times_i S_i$. The individual pure strategy space is defined as
$S_i = \{1,2,...,m_i\}$, where $m_i \in \mathbb{N}$ denotes the total 
number of strategies available to player $i$. 
The payoff 
function of the game is denoted by $F: S \rightarrow \realnumb^n$.
As this text focuses upon the stag hunt game, these definitions reduce to the 
following.
By setting $n=2$, we define the set of two hunters playing SH as $I=\{1,2\}$. 
In the SH game, each hunter can choose one out of two pure strategies, namely, 
hunting stag (strategy 1 or S) or hunting hare (strategy 2 or H).
Therefore, the pure strategy space is defined by $S_i = \{1,2\}$, which results
by setting $m_i=2$. 
The strategies are called pure to distinguish
them from the later introduced mixed strategies. 
In the SH game both players choose from
the same set of strategies such that $S_1 =S_2=S$. Combining the strategy spaces
of the two players with the cartesian product
yields the definition of the pure strategy space of the game
$\mathbb{S}= S \times S = S^2$. Games played by two players with two strategies
each, are often said to be 2x2 games.    

Considering the story Rousseau told, the hunters do not just hunt
for their pleasure, but to sell their loot for a reward or to feed their 
families. 
This is captured by the definition of an individual payoff function for player
i, $F_i:S \rightarrow \realnumb$, which maps a payoff $F_i(s) \in \realnumb$ 
to every state of the game $s=(s_1,s_2) \in S^2$, where $s_i$ is a pure
strategy of player $i$. A state of the game $s$ is sometimes simply called 
strategy profile.
The payoffs are usually interpreted as \textit{von-Neumann} utility when 
played by individuals or households and may be interpreted as earnings 
regarding firms \parencite{fudenberg_theory_1998}. 

In the special case of two players, one can define a payoff matrix for
player 1, $A \in \realnumb^{2 \times2}$ and for player 2,
$B \in \realnumb^{2 \times2}$. The elements of the matrices $A_{kl}$ and
$B_{kl}$ state the payoffs to the players for a given strategy profile. 
Hence, the elements are defined as $A_{kl}= F_1(k,l)$ and 
$B_{kl} =F_2(k,l)$ with the pure strategies $k,l \in S$.
Using the 
representation in figure \ref{fig:parash}, one can identify the 
payoff matrices for the players as
\begin{align}
     A = \mqty(a && b \\ c && d), \quad B = \mqty(a && c \\ b && d).
        \label{eq:matrix}
\end{align}
For the SH game studied in this thesis, the following definition is important: 
\begin{mydef}
        A two player game $\Gamma=(I,S_1 \times S_2, A,B)$ is called symmetric
        if the players of the game have the same strategy space $S_1=S_2=S$ and
        for the payoff matrices the condition $B=A^T$ holds. Therefore, the
        game is well-defined as $\Gamma=(I,S^2,A)$.
        \label{symmetry}
\end{mydef}
Clearly, the SH game satisfies this condition. Both hunters have the same 
strategies available and the payoff matrices defined in equation
\eqref{eq:matrix} are the transpose of the other.
Hence, it is irrelevant which player is labeled as player 1 or 2, because 
they are identical with respect to their strategies and payoffs.

Usually a game is extended by the possibility of the players to play
\textit{mixed strategies}. 
Intuitively, the hunters in the SH game could  
choose whether to shoot the stag or the hare by using a randomization
tool such as flipping a coin. However, randomization is not really
satisfying in most applications \parencite{radner_private_1982}. An
alternative interpretation, outlined by Rubinstein, is that mixed 
strategies are actually deterministic, but seem to be random because they 
depend on not modelled private information of the individuals 
\parencite[914]{rubinstein_comments_1991}. In the evolutionary context,
discussed in section \ref{sec:evolutionarystaghunt}, mixed strategies have
a different, unproblematic interpretation. Apart from the interpretation 
problem, mixed strategies are appealing because they ensure the existence
of a Nash equilibrium, which is defined later in section 
\ref{sec:traditionalconcepts}.
Formally, every player of the game assigns a probability distribution over
his pure strategies space. A strategy $x_i \in \Delta_i$ of 
player $i \in I$ is called a \textit{mixed strategy}, where $\Delta_i$ is 
the mixed strategy space 
\begin{align*}
        \Delta_i = \{ x_i = (x_{i1}, x_{i2})^T \in \realnumb^2 : 
                \sum_{k=1}^2 x_{ik} = 1, x_{ik} \geq 0 \quad
\forall k \in S\}.
\end{align*}
In a symmetric game, the mixed strategy spaces of the players are
equal, as both players are not restricted in assigning probabilities to their
pure strategies. For the SH game this means $\Delta_1 = \Delta_2 = \Delta$.
With this notation, a pure strategy can be interpreted as a mixed strategy,
that assigns probability one to the pure strategy chosen and zero to all
other strategies. This is represented by the unit vectors 
$e_k \in \Delta$, where $k \in \{1,2\}$. 
Hence, $e_1 = (1,0)^T$ is the pure strategy hunting stag 
and $e_2 =(0,1)^T$ denotes the pure strategy hunting hare.
The combined mixed strategy space of the game is $\Delta^2 = \Delta \times
\Delta$.
From now on, except otherwise indicated, $x \in \Delta$ 
denotes a (mixed) strategy
chosen by player 1 and $y \in \Delta$ a (mixed) strategy of player 2.
Again, similar to the pure strategy case, the mixed strategy payoff 
$\hat{F}_i:\Delta^2 \rightarrow \realnumb$ maps 
any state in the mixed strategy
space  $(x,y) \in \Delta^2$ to an expected payoff 
$\hat{F}_i(x,y) \in \realnumb$.
With the matrix notation this is defined as: 
\begin{alignat*}{2}
        \hat{F}_1(x,y) &= x^T A y \\
        \hat{F}_2(x,y) &= x^T A^T y 
\end{alignat*}
Summarizing the notation, the SH game can be defined as a symmetric two-player
normal form game $\Gamma = (I=\{1,2\}, \Delta^2, \hat{F})$.

\subsection{Solution Concepts}
\label{sec:traditionalconcepts}
In describing the behavior of agents, game theory developed a wide range of 
tools to solve these strategic interactions. First of all, for each individual
a best-reply is defined by simply describing the strategies available to the
agent which yield the highest expected payoff against a given 
strategy of the other player.
Formally, the \textit{best-reply} $\beta_i(y)$ for player $i \in I$ to a 
strategy $y \in \Delta$ played by $j \neq i$ is defined as:
\begin{align}
        \label{eq:bestreply}
        \beta_i(y) = \{x \in \Delta: \hat{F}(x,y) \geq \hat{F}(x',y), 
        \quad \forall x' \in \Delta\}
\end{align}
Based on agents choosing a best-reply, the most frequently 
used solution concept of
a normal form game is the \textit{Nash equilibrium}.
The Nash equilibrium was named by its proposer John Nash in 1950 
and due to its prominence it is sometimes simply referred to as equilibrium 
or NE.
In the following, the definition of a Nash equilibrium in a two
player normal form game is stated. 
\begin{mydef}
        \label{def:nashequilibrium}
        A state of $(x^*,y^*) \in \Delta^2$ is called a Nash equilibrium if 
        it holds that
        \begin{alignat*}{2}
                (x^*)^T A y^* &\geq x^T A y^*, \quad \forall x \in \Delta  \\
                (x^*)^T A^T y^* &\geq (x^*)^T A^T y \quad \forall y \in \Delta
        \end{alignat*}
It is called symmetric if $x^* = y^*$. A Nash equilibrium is called a 
strict Nash equilibrium if the inequality is strict.
\end{mydef}
Actually, only one inequality is needed in a symmetric game as payoffs
and strategy spaces are identical and so every state $(y^*,x^*) \in \Delta^2$ 
is also a Nash equilibrium.
Equivalently to the definition, one can say that a strategy profile 
is a Nash equilibrium if all players choose a best-reply in that state of 
the game and hence, no player has the incentive to deviate from his 
choice given the choice of the other players.
\textcite{nash_equilibrium_1950} proved the existence of such 
an equilibrium in any normal form game with mixed strategies. 
Imposing the Nash equilibrium as a solution concept implies that 
agents are \textit{perfectly rational} and have \textit{common knowledge} 
of the payoff matrix and the strategies available to all other players. 
In the stag hunt game, this means that players are able to calculate every
outcome and additionally know that other players are rational and 
consequently also know that other players know that 
they are rational and so forth \parencite{fudenberg_theory_1998}. 
Furthermore, it is assumed that they strive to maximize their own payoff.

Analyzing the SH game, one finds three symmetric Nash equilibria.
The first one consists of both players choosing strategy 1, 
hunting stag, $(e_1,e_1) \in
\Delta^2$, where both players receive the payoff $(a)$. 
None of them has an incentive to change his decision as for both
playing the pure strategy 1 is a best-reply. A unilateral deviation would 
lead to the payoff $c\ (< a)$.
The second equilibrium is the state of 
both players choosing strategy 2, hunting hare, $(e_2,e_2)
\in \Delta^2$. Again, by definition, both play a best-reply and a unilateral 
deviation of a player results in a lower payoff $b<d$.
Additionally to these Nash equilibria in pure strategies, there is a symmetric
mixed strategy equilbrium where both players assign a probability 
$q^*=\left(\frac{d-b}{a-c+d-b}\right)$ to strategy 1. 
To see this, a player is indifferent between choosing one of his pure
strategies against $y$, $\hat{F}(e_1,y^*) = \hat{F}(e_2,y^*)$, exactly
when $y^*=(q^*,1-q^*)^T$. The best-reply for a player against $y^*$ can 
be obtained by equating the partial derivative of his payoff function 
with 0 at $y=y^*$, 
$\eval{\frac{\partial \hat{F}(x,y)}{\partial y}}_{y=y^*} = 0$.
One finds that the best-reply is also $x=y^*$. 

For further analysis it is convenient to use the fact that Nash equilibria 
are only defined by comparison of payoff differences. 
Hence, any affine transformation of the payoff matrix does not change the 
best-replies of the players and thus, does not affect the set of Nash equilibria 
of the game \parencite[17-19]{weibull_evolutionary_1997}. 
Furthermore, adding a constant to every entry in a 
column of the payoff matrix, 
called a \textit{local shift}, does not affect the payoff differences
a player considers when valuating which strategy is better against a given
strategy of the other player.
Formally, let $A_{kl}$ denote the elements of the player's payoff matrix. 
A local shift to column $l^*$ transforms this payoff matrix into the payoff 
matrix $A^*$:
\begin{align*}
        A^*_{kl} =
        \begin{cases}
                A_{kl} + v & \text{,\ for}\ l=l^*, v \in \realnumb \\
                A_{kl} & \text{,\ else}
        \end{cases}
\end{align*}
Applying this to the stag hunt game, one can use two local shifts to turn 
the payoff matrix into a diagonal matrix with elements $A_{11}=\alpha_1$ 
and $A_{22}=\alpha_2$, where $\alpha_1=(a-c)$ and $\alpha_2=(d-b)$. 
\textcite[28]{weibull_evolutionary_1997} groups all symmetric 2x2 games into 
four categories with different equilibrium properties. 
The stag hunt game is considered a coordination 
game, with $\alpha_1, \alpha_2 > 0$ and in contrast to the class of games
with dominated strategies, for example the PD, the solution of the game
is not that obvious as there are multiple Nash equilibria.
This will be further discussed in section \ref{sec:equilibriumselection}.

\subsection{Evolutionary Solution Concept}
The stag hunt game has two Nash equilibria. When a game exhibits 
multiple equilibria it seems to be a reasonable question 
which equilibrium will be played. To answer this, 
game theorists tried to construct refinements 
of the Nash equilibrium in cases where some equilibria were unconvincing. 
Motivated by the context of evolution in animal populations 
\textcite{smith_lhe_1973} constructed the refinement of an 
\textit{evolutionary stable strategy} (ESS).  
In the biological context of \textcite{smith_lhe_1973}, a game is played 
by animals that are of a specific phenotype. A phenotype is interpreted
as a strategy in the underlying game. The animals of the population are randomly
matched in pairs, playing the normal form game. Payoffs are interpreted as
\textit{Darwinian fitness}, the number of expected offspring to a phenotype.
Hence, the payoffs determine the survivability of the phenotype in the 
population.
The ESS concept answers the question which compositions of the population are
stable against an invasion by other animals from outside.
\begin{mydef}
        \label{def:ess}
        A strategy $x \in \Delta$ is called a evolutionary stable strategy 
        (ESS) if it holds that
        \begin{alignat}{2}
                \hat{F}(x,x) &\geq \hat{F}(y,x) \quad \forall y \label{eq:essstrict} \\
                \hat{F}(y,x) &= \hat{F}(x,x) \Rightarrow  
                \hat{F}(x,y) > \hat{F}(y,y) \quad \forall y \neq x \label{eq:essstrict2}
        \end{alignat}
\end{mydef}
Equation \eqref{eq:essstrict}
requires an ESS $x$ to be a better reply to itself than any other strategy $y$.
If there exists a strategy $y$ with the same payoff, equation 
\eqref{eq:essstrict2} demands that choosing $x$ against $y$ is better 
than choosing $y$ against itself.
Indeed, an ESS is used in a 
Nash equilibrium as it needs to be a best-reply to satisfy the 
condition in equation \eqref{eq:essstrict}. 
In addition, a strategy used in a strict 
Nash equilibrium is always an ESS, since it strictly satisfies 
\eqref{eq:essstrict}. 
In the stag hunt game, not all strategies are evolutionary stable.
The pure strategies $e_1$ and $e_2$ are evolutionary stable,
since both are used in a strict symmetric Nash equilibria and thereby 
satisfy condition \eqref{eq:essstrict} strictly. 
Now let $y$ denote the strategy in the mixed NE $y=(q^*,1-q^*)^T$, 
with $q=\left(\frac{\alpha_2}{\alpha_1+\alpha_2}\right)$.
To prove that a strategy is not an ESS it suffices to find one
strategy for which the inequalities do not hold.
For example consider strategy $e_1$.
The payoff against strategy $y$ is, independently of the other strategy, 
equal to $\left(\frac{\alpha_2 \alpha_1}{\alpha_2+\alpha_1}\right)$, i.e.\ 
\eqref{eq:essstrict} is an equality.
Proceeding with \eqref{eq:essstrict2}, one finds
$\hat{F}(y,e_1) = \frac{\alpha_1 \alpha_2}{\alpha_1+\alpha_2}
< \alpha_1 = \hat{F}(e_1,e_1)$, implying that $y$ is not an ESS.
Hence, the concept of an ESS does not help to select one 
unique solution in the stag hunt game. However, its importance for
evolutionary game theory will be put into sharper relief when considering
evolutionary dynamics in section \ref{sec:evolutionarystaghunt}. 


\subsection{Equilibrium Selection}
\label{sec:equilibriumselection}
Clearly, game theory has the aspiration to provide an unique solution for 
every strategic interaction.
As seen in the stag hunt game, the most frequently used solution concept, 
the Nash equilibrium, and refinements such as the ESS are
not sufficient to select a unique equilibrium, even in the case of a simple
2x2 SH game. This does not satisfy game theorists, since it is not clear which
equilibrium is eventually played by the agents. Or how 
Weibull puts it, this kind of coordination games 
``caused\footnote{And still causes.} game theorists and users of 
noncooperative game theory a fair amount of frustration'' 
\parencite[30]{weibull_evolutionary_1997}. 

A closer look at the two pure Nash equilibria in the Stag hunt game 
shows their difference. Considering the normal form representation in figure 
\ref{fig:sh}, the Nash equilibrium in which both players choose strategy one 
has the highest payoff
for both players. $(e_1,e_1)$ is then said to 
\textit{payoff-dominate} or to \textit{Pareto-dominate} 
$(e_2,e_2)$. Equivalently, the equilibria are said to be
\textit{Pareto-ranked}.
In the prisoner's dilemma, briefly described in the introduction, 
the payoff-dominant outcome is not a 
Nash equilibrium, due to the fact that every agent has the incentive to 
deviate and accept the deal of the authority.
On the contrary, in the SH game every agent plays a best-reply 
in the Pareto efficient outcome, but since there is another Nash equilibrium 
it is not clear which one is played based on equilibrium play alone. 
Following \textcite[57]{schelling_strategy_1960}, one may argue that 
Pareto-dominance characterizes $(e_1,e_1)$ as a focal point. 
A focal point is an outcome of a game that is psychologically prominent and
hence, might attract players.

However, the equilibrium point $(e_2,e_2)$ exhibits a property
called \textit{risk\hyp{}dominance}. 
Consider the numerical example in figure \ref{fig:numericalsh}. 
Strategy $H$ ensures a player with a payoff of at least $3$, whereas the 
payoff for strategy S varies between $5$ and $0$. Undoubtedly, 
strategy $H$ is less risky than strategy $S$ if a player is unsure 
about the strategy choice of the other player.
\textcite{harsanyi_general_1988} defined this selection criterion 
based on the risk for the players associated with an 
equilibrium point using a tracing procedure. 
Basically, in this tracing procedure agents use common knowledge
to form new beliefs about the choice of their opponent, considering that
the opponent also has a less risky strategy.
It is noteworthy that ``risk-dominance is theoretically completely unrelated
to risk aversion'' as on one hand, the payoffs are in terms of von-Neumman
utility and on the other hand, proceeding with the updating of their beliefs
using common knowledge finally leaves the agents with certainty that the less 
risky strategy will be played by their opponent 
\parencite[341]{straub_risk_1995}.
A detailed discussion of the tracing procedure is beyond the scope of this
text. Nevertheless, risk-dominance is easily defined for the SH game.
\begin{mydef}
 \label{eq:riskdom}
The Nash equilibrium $(e_2,e_2)$ \textit{risk-dominates} 
$(e_1,e_1)$, if $(d-b)^2 > (a-c)^2$. \end{mydef}
The squares on the left and the right side of the inequality are named
\textit{Nash products}.
As mentioned in \textcite{weibull_evolutionary_1997}, a Nash equilibrium 
risk-dominates if it is Pareto-dominant in the 
normalized payoff version of the game, 
associated with the diagonal payoff matrix, 
as definition \eqref{eq:riskdom} corresponds to $\alpha_1 < \alpha_2$.

Therefore, both pure Nash equilibria have a 
certain appeal for game theorists to be
favored as an outcome of the game. 
The question is whether people rather play
safe and coordinate on the hare hunting equilibrium, terminating in a social
dilemma as there exists an outcome in which everyone of them is better off.
Or whether they are able to recognize the payoff-dominance of stag hunting, 
trusting each other not to react to a hare passing by.
Indeed, there is no consensus which equilibrium will be played. 
Although \textcite{harsanyi_general_1988} introduced the 
risk-dominance criterion, their general theory of equilibrium 
selection favors payoff-dominance in the SH game. They argue that
``if each player knows the other to be fully rational [...] they should trust
each other to play'' strategy $S$ \parencite[89]{harsanyi_general_1988}.
Furthermore, Harsanyi and Selten expect players to coordinate on the
Pareto-dominant equilibrium if they are allowed to communicate beforehand,
sometimes referred to as \textit{cheap talk} when it does not directly affect
the payoffs \parencite[104]{farrell_cheap_1996}, 
because ``an agreement to do so is self-stabilizing''. 
In contrast to that,
\textcite{aumann_nash_1990} points out that a message from player 1 to 
player 2, saying that he intends to coordinate on the payoff-dominant 
equilibrium, does not in general contain useful information for player 2. 
Indeed, in the numerical example of the SH game in figure \ref{fig:numericalsh} 
a player wants his
opponent to choose strategy $S$ independently of his choice, because
hare hunting alone is better (payoff:\ $4$) than hare hunting together 
(payoff:\ $3$).
Despite this argument, 
\textcite[114]{farrell_cheap_1996} expect that 
``cheap talk will do a good deal to
bring Artemis and Calliope\footnote{The names
\textcite{farrell_cheap_1996} used for player 1 and player 2.} 
to the stag hunt''. The experimental evidence will give a hint on how cheap
talk affects real players. 
``Convinced by Aumann's argument'', Harsanyi formulated a new theory
of equilibrium selection in 1995, solely focussing on 
risk-dominance as selection criterion, hence favoring the hare 
equilibrium in the SH game \parencite[92,94,96]{harsanyi_new_1995}. 

In the social sciences, the infinitely repeated version of the
prisoner's dilemma has attracted wide interest for studying which factors 
affect cooperation. The famous book ``The evolution of cooperation'' by Robert
Axelrod studies the success of different strategies using computer 
simulations of the repeated prisoner's dilemma. The typical theoretical
framework usually only recognizes the Pareto-dominance of some equilibria
in the repeated game. Intriguingly, \textcite{blonski_prisoners_2015} show
that the underlying structure actually is similiar to the stag hunt game, 
as risk-dominance and Pareto-dominance select different equilibria. 
This connection to 
one of the most frequently used frameworks of a social dilemma stresses the
importance of the equilibrium selection problem in the stag hunt game.

The evolutionary analysis outlined in the next section gives an answer
to the equilibrium selection problem. Moreover, the answer is directly
connected to the risk-dominance criterion.
